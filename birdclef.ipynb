{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9da5ffe",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61846c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os \n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import datasets, models, transforms\n",
    "import json\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "from IPython.display import Image\n",
    "import IPython.display as ipd\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "import random\n",
    "import gc\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a639c526",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c4ce974",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_pt_DIR = './train_pt'\n",
    "Train_Metadata_DIR = './train_metadata.csv'\n",
    "Scored_Bird_DIR ='./scored_birds.json'\n",
    "Train_DIR = './train_audio/'\n",
    "Audio_Rating_Dir = \"./bird_audio_rating_mapping.pkl\"\n",
    "\n",
    "#read in metadata as df\n",
    "train_df = pd.read_csv(Train_Metadata_DIR)\n",
    "train_df.head()\n",
    "train_df['dir'] = Train_DIR+train_df['filename']\n",
    "#print(train_df['dir'])\n",
    "tqdm.pandas()\n",
    "#train_df['spectogram'] = train_df.progress_apply(lambda x: process_audio_to_spectogram(x['dir']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08321fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nnum_audio_files = train_df.shape[0]\\n\\nspectograms_list = []\\nfor i in tqdm(range(100)):\\n    current_bird = train_df.primary_label.loc[i]\\n    process_get_audio_chunks_images(train_df['dir'].iloc[i])\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "num_audio_files = train_df.shape[0]\n",
    "\n",
    "spectograms_list = []\n",
    "for i in tqdm(range(100)):\n",
    "    current_bird = train_df.primary_label.loc[i]\n",
    "    process_get_audio_chunks_images(train_df['dir'].iloc[i])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "863d51f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectograms_from_file(idx):\n",
    "    #get all the corresponding spectogram in np format\n",
    "    bird = idx2bird[idx]\n",
    "    pt_filepath = Train_pt_DIR+\"/\"+bird+\".pt\"\n",
    "    x_train = torch.load(pt_filepath).view(-1,1,128,216)\n",
    "    num_training_samples = x_train.shape[0]\n",
    "    #y_train is one hot encoded vector per training sample\n",
    "    y_train = torch.tensor(np.array([0]*len(all_birds))).view(1,-1)\n",
    "    y_train[0,idx] = 1\n",
    "    y_train = torch.cat([y_train]*num_training_samples)\n",
    "\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "311c201d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_training_spectograms_from_file(idx, n_spectograms, TRAINING_VAL_SPLIT):\n",
    "    #get n random spectogram (np format) of selected bird\n",
    "    bird = idx2bird[idx]\n",
    "    pt_filepath = Train_pt_DIR+\"/\"+bird+\".pt\"\n",
    "    x_train = torch.load(pt_filepath).view(-1,1,128,216) # to convert to N,C, H, W format\n",
    "    \n",
    "    train_index = int(TRAINING_VAL_SPLIT*len(x_train)) #80:20 split for training and validation\n",
    "    \n",
    "    indices = torch.randint(0,train_index,(n_spectograms,)) #only sample from training pool\n",
    "    selected_X_train = x_train[indices]\n",
    "    \n",
    "    y_train = torch.tensor(np.array([0]*len(all_birds))).view(1,-1)\n",
    "    y_train[0,idx] = 1\n",
    "    selected_y_train = torch.cat([y_train]*n_spectograms)\n",
    "    \n",
    "    return selected_X_train, selected_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a068e157",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './train_pt/hudgod.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18184/3782068452.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./train_pt/hudgod.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./train_pt/redpha1.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    697\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoding'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'w'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './train_pt/hudgod.pt'"
     ]
    }
   ],
   "source": [
    "a = torch.load('./train_pt/hudgod.pt')\n",
    "print(a.shape)\n",
    "b = torch.load('./train_pt/redpha1.pt')\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fae65b4",
   "metadata": {},
   "source": [
    "### Noise Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1ffbbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_reduction(y, sr, plot=True, th=0.3):\n",
    "    from scipy.fft import fft, fftfreq, ifft\n",
    "    \n",
    "    SAMPLE_RATE = 1\n",
    "    DURATION = len(y) / SAMPLE_RATE\n",
    "    N = int(SAMPLE_RATE * DURATION)\n",
    "\n",
    "    yf = fft(y)\n",
    "    xf = fftfreq(N, 1 / SAMPLE_RATE)\n",
    "    \n",
    "    if plot:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(24, 8))\n",
    "        axes[0].plot(np.arange(len(y)), y)\n",
    "        axes[0].set_title('Before Time-Domain')\n",
    "        axes[1].plot(xf, np.abs(yf))\n",
    "        axes[1].set_title('Before Frequency-Domain')\n",
    "        plt.show()\n",
    "    \n",
    "    # Filtering Low-Pass\n",
    "    new_yf = yf.copy()\n",
    "    middle = len(y) / 2\n",
    "    new_yf[int(middle - len(y) * th):int(middle + len(y) * th)] = 0\n",
    "    new_y = ifft(new_yf)\n",
    "    new_y = new_y.real\n",
    "    \n",
    "    if plot:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(24, 8))\n",
    "        axes[0].plot(np.arange(len(y)), new_y)\n",
    "        axes[0].set_title('After Time-Domain')\n",
    "        axes[1].plot(xf, np.abs(new_yf))\n",
    "        axes[1].set_title('After Frequency-Domain')\n",
    "        plt.show()\n",
    "\n",
    "    return new_y, sr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6cb58e",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5f75b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of birds 152\n"
     ]
    }
   ],
   "source": [
    "all_birds = list(train_df.primary_label.dropna().unique())\n",
    "print('Total number of birds',len(all_birds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc1b1496",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for mapping of bird (str) to idx (int)\n",
    "bird2idx = {}\n",
    "for i, bird in enumerate(all_birds):\n",
    "    bird2idx[bird] = i\n",
    "    \n",
    "idx2bird = {}\n",
    "for _, (k, v) in enumerate(bird2idx.items()): \n",
    "    idx2bird[v] = k "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b9c7216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2bird[151]\n",
    "bird2idx['zebdov']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4e9738f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of birds 152\n",
      "Scored birds ['akiapo', 'aniani', 'apapan', 'barpet', 'crehon', 'elepai', 'ercfra', 'hawama', 'hawcre', 'hawgoo', 'hawhaw', 'hawpet1', 'houfin', 'iiwi', 'jabwar', 'maupar', 'omao', 'puaioh', 'skylar', 'warwhe1', 'yefcan']\n",
      "Number of scored birds training files \n",
      " akiapo      14\n",
      "aniani      12\n",
      "apapan      47\n",
      "barpet      15\n",
      "crehon       2\n",
      "elepai      14\n",
      "ercfra       6\n",
      "hawama      21\n",
      "hawcre      20\n",
      "hawgoo       9\n",
      "hawhaw       3\n",
      "hawpet1      3\n",
      "houfin     322\n",
      "iiwi        37\n",
      "jabwar      78\n",
      "maupar       1\n",
      "omao        21\n",
      "puaioh       3\n",
      "skylar     500\n",
      "warwhe1     71\n",
      "yefcan      67\n",
      "Name: primary_label, dtype: int64\n",
      "\n",
      "Number of training files per bird\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_birds = list(train_df.primary_label.dropna().unique())\n",
    "print('Total number of birds',len(all_birds))\n",
    "\n",
    "#load scored birds \n",
    "with open(Scored_Bird_DIR) as sbfile:\n",
    "    scored_birds = json.load(sbfile)\n",
    "print('Scored birds',scored_birds)\n",
    "\n",
    "bird_training_sample = train_df.primary_label.value_counts()\n",
    "\n",
    "print('Number of scored birds training files \\n',bird_training_sample.loc[scored_birds])\n",
    "print()\n",
    "print('Number of training files per bird')\n",
    "bird_training_sample.plot(kind='barh')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dab7b538",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/152 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './train_pt/afrsil1.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18184/1634106935.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mnum_training_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mbird\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_birds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_bird\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_spectograms_from_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbird2idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbird\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mnum_training_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbird\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train_bird\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0msorted_training_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_training_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mkv\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mkv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18184/582581834.py\u001b[0m in \u001b[0;36mget_spectograms_from_file\u001b[1;34m(idx)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mbird\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0midx2bird\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mpt_filepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrain_pt_DIR\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbird\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\".pt\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpt_filepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m216\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mnum_training_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m#y_train is one hot encoded vector per training sample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    697\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoding'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'w'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './train_pt/afrsil1.pt'"
     ]
    }
   ],
   "source": [
    "#EDA, did the number of training data (5s) per bird\n",
    "num_training_data = {}\n",
    "for bird in tqdm(all_birds):\n",
    "    _, y_train_bird = get_spectograms_from_file(bird2idx[bird])\n",
    "    num_training_data[bird] = len(y_train_bird)\n",
    "sorted_training_data = sorted(num_training_data.items(), key = lambda kv: kv[1])\n",
    "print(sorted_training_data)\n",
    "\n",
    "scored_bird_training = {}\n",
    "for bird in tqdm(scored_birds):\n",
    "    scored_bird_training[bird] = num_training_data[bird]\n",
    "sorted_scored_bird_training_data = sorted(scored_bird_training.items(), key = lambda kv: kv[1])\n",
    "print(sorted_scored_bird_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0579ea31",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sorted_training_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18184/1330438804.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msorted_training_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msorted_scored_bird_training_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sorted_training_data' is not defined"
     ]
    }
   ],
   "source": [
    "x, y = zip(*sorted_training_data) \n",
    "plt.plot(x, y)\n",
    "plt.show()\n",
    "\n",
    "x, y = zip(*sorted_scored_bird_training_data) \n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9460921",
   "metadata": {},
   "source": [
    "### Generate training data in .pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b41035d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectograms(filename):\n",
    "    chunk_duration = 5 #5sec chunk\n",
    "    duration = librosa.get_duration(filename=filename)\n",
    "    num_spectogram = int(duration/chunk_duration)\n",
    "    spectograms = []\n",
    "    for i in range(num_spectogram):\n",
    "        y, sr = librosa.load(filename, offset=i*chunk_duration, duration=chunk_duration)\n",
    "        #display(\"Old Audio\", ipd.Audio(data=y, rate=sr))\n",
    "        nr_y, nr_sr = noise_reduction(y, sr, plot=False, th=0.3)\n",
    "        #display(\"New Audio\", ipd.Audio(data=nr_y, rate=sr))\n",
    "        S = librosa.feature.melspectrogram(y=nr_y, sr=nr_sr)\n",
    "        S_DB = librosa.power_to_db(S, ref=np.max)\n",
    "        spectograms.append(S_DB)\n",
    "    return spectograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff9c339",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|        | 1674/14852 [28:06<42:04:30, 11.49s/it]"
     ]
    }
   ],
   "source": [
    "#generate pt files\n",
    "num_audio_files = train_df.shape[0]\n",
    "\n",
    "spectograms_list = []\n",
    "for i in tqdm(range(num_audio_files)):\n",
    "    current_bird = train_df.primary_label.loc[i]\n",
    "    #print('previous_bird',previous_bird)\n",
    "    #print('current_bird',current_bird)\n",
    "    spectograms_list += get_spectograms(train_df['dir'].iloc[i])\n",
    "    if i+1 == num_audio_files:\n",
    "        torch.save(torch.tensor(np.array(spectograms_list)), './train_pt/'+current_bird+'.pt')\n",
    "    else:\n",
    "        next_bird = train_df.primary_label.loc[i+1]\n",
    "        #print('next_bird',next_bird)\n",
    "        if next_bird != current_bird:\n",
    "            torch.save(torch.tensor(np.array(spectograms_list)), './train_pt/'+current_bird+'.pt')\n",
    "            spectograms_list = []\n",
    "    previous_bird = current_bird\n",
    "    #print(spectograms_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913a4ddf",
   "metadata": {},
   "source": [
    "### Get the audio rating for each of the training sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a25d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "num_audio_files = train_df.shape[0]\n",
    "\n",
    "def get_num_spectograms_per_audio(filename):\n",
    "    chunk_duration = 5 #5sec chunk\n",
    "    duration = librosa.get_duration(filename=filename)\n",
    "    num_spectogram = int(duration/chunk_duration)\n",
    "    \n",
    "    return num_spectogram\n",
    "\n",
    "bird_audio_rating_mapping = {}\n",
    "audio_rating_list = []\n",
    "for i in tqdm(range(num_audio_files)):\n",
    "    current_bird = train_df.primary_label.loc[i]\n",
    "    audio_rating = train_df['rating'].iloc[i]\n",
    "    if audio_rating == 0:\n",
    "        audio_rating = 2.5\n",
    "    num_spec = get_num_spectograms_per_audio(train_df['dir'].iloc[i])\n",
    "    audio_rating_list += [audio_rating]*num_spec\n",
    "    if i+1 == num_audio_files:\n",
    "        bird_audio_rating_mapping[current_bird] = audio_rating_list\n",
    "        #torch.save(torch.tensor(np.array(spectograms_list)), './train_pt/'+current_bird+'.pt')\n",
    "    else:\n",
    "        next_bird = train_df.primary_label.loc[i+1]\n",
    "        if next_bird != current_bird:\n",
    "            bird_audio_rating_mapping[current_bird] = audio_rating_list\n",
    "            #torch.save(torch.tensor(np.array(spectograms_list)), './train_pt/'+current_bird+'.pt')\n",
    "            audio_rating_list = []\n",
    "    previous_bird = current_bird\n",
    "\n",
    "#save the mapping into file\n",
    "rating_file = open(\"bird_audio_rating_mapping.pkl\", \"wb\")\n",
    "pickle.dump(bird_audio_rating_mapping, rating_file)\n",
    "rating_file.close()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406a07a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_file = open(Audio_Rating_Dir, \"rb\")\n",
    "bird_audio_rating_mapping = pickle.load(rating_file)\n",
    "#print(bird_audio_rating_mapping)\n",
    "rating_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfaedf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bird_audio_rating_mapping['blknod'])\n",
    "print(len(bird_audio_rating_mapping['blknod']))\n",
    "print((num_training_data['blknod']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841678bc",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ce365a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_seq = [i for i in range(len(all_birds))]\n",
    "random.shuffle(training_seq)\n",
    "print(training_seq)\n",
    "print()\n",
    "training_seq_bird = [idx2bird[i] for i in training_seq]\n",
    "print(training_seq_bird)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deded270",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46592f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = r-a  # free inside reserved\n",
    "print(t)\n",
    "print(r)\n",
    "print(a)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4edca49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For upsampling / downsampling / mixup of data\n",
    "TRAINING_THRESHOLD_UPSAMPLING = 512\n",
    "TRAINING_THRESHOLD_DOWNSAMPLING = 512 * 2\n",
    "TRAINING_MIXUP_PERCENTAGE = 0.2 #0.2 means 20% of the training data (after up and down sampling) will be mixup \n",
    "TRAINING_SPECAUGMENT_PERCENTAGE = 0.2 #0.2 means 20% of the training data (after up and down sampling) will be spec-augment \n",
    "TRAINING_VAL_SPLIT = 0.8 #0.8 means 80% of training data will be considered for training, 20% for validation (untouched)\n",
    "\n",
    "def get_more_samples_raw(X_train_bird,y_train_bird,additional_num_samples,rating_weights):\n",
    "    #x train\n",
    "    #e.g. i need 512, but i only have 500\n",
    "    #total_samples = len(y_train_bird)\n",
    "    indices = torch.multinomial(rating_weights,additional_num_samples,replacement=True) #generate the random index, \n",
    "    #e.g. [0,99,54,46,56,35,245,6,8,8,2]\n",
    "    #indices = torch.randint(0,total_samples,(additional_num_samples,))\n",
    "\n",
    "    additional_X_train_bird = X_train_bird[indices]\n",
    "    additional_y_train_bird = y_train_bird[indices]\n",
    "    \n",
    "    return additional_X_train_bird, additional_y_train_bird\n",
    "\n",
    "def get_down_samples(X_train_bird,y_train_bird,num_samples,rating_weights):\n",
    "    #x train\n",
    "    # i got 2000 samples, retrieve only 1024\n",
    "    indices = torch.multinomial(rating_weights,num_samples)\n",
    "\n",
    "    updated_X_train_bird = X_train_bird[indices]\n",
    "    updated_y_train_bird = y_train_bird[indices]\n",
    "    \n",
    "    return updated_X_train_bird, updated_y_train_bird\n",
    "\n",
    "def get_mixup_samples(X_train_bird,y_train_bird,num_mixup_sample,rating_weights,TRAINING_VAL_SPLIT):\n",
    "    \n",
    "    #randomly select indices from bird type 1\n",
    "    source_indices = torch.randint(0,len(y_train_bird),(num_mixup_sample,))\n",
    "    source_X_train = X_train_bird[source_indices]\n",
    "    source_y_train = y_train_bird[source_indices]\n",
    "\n",
    "    #--- TARGET BIRD ---\n",
    "    #randomly select target bird type to mixup\n",
    "    target_bird = torch.randint(0,len(all_birds),(num_mixup_sample,)) #output [10,4,7,64,32]\n",
    "    bird_count = torch.bincount(target_bird) # output from bird1 - 4 times, bird 2 - 20 times \n",
    "    \n",
    "    #initialise empty tensor\n",
    "    target_X_train = torch.empty(0,X_train_bird.shape[1],X_train_bird.shape[2],X_train_bird.shape[3]) # N, C , H, W\n",
    "    target_y_train = torch.empty(0,len(all_birds))\n",
    "    for i in range(len(bird_count)):\n",
    "        if bird_count[i] >0:\n",
    "            add_target_X_train, add_target_y_train = get_n_training_spectograms_from_file(i, bird_count[i],TRAINING_VAL_SPLIT) #touched val_data, to be revised\n",
    "            target_X_train = torch.cat((target_X_train,add_target_X_train),0)\n",
    "            target_y_train = torch.cat((target_y_train,add_target_y_train),0)\n",
    "    \n",
    "    #Perform Mixup for source and target bird entries\n",
    "    mixup_X_train = torch.zeros(num_mixup_sample,X_train_bird.shape[1],X_train_bird.shape[2],X_train_bird.shape[3])\n",
    "    mixup_y_train = torch.zeros_like(target_y_train)\n",
    "    for i in range(len(source_indices)):\n",
    "        lambda_factor = torch.randn(1) \n",
    "        mixup_X_train[i] = source_X_train[i]*lambda_factor + target_X_train[i]*(1-lambda_factor)\n",
    "        mixup_y_train[i] = source_y_train[i]*lambda_factor + target_y_train[i]*(1-lambda_factor)\n",
    "\n",
    "    return mixup_X_train, mixup_y_train\n",
    "\n",
    "def spec_augment(spec, num_mask=1, \n",
    "                 freq_masking_max_percentage=0.1, time_masking_max_percentage=0.1):\n",
    "    \n",
    "    spec = spec.detach().clone()\n",
    "    for i in range(num_mask):\n",
    "        all_frames_num, all_freqs_num = spec.shape\n",
    "        freq_percentage = random.uniform(0.0, freq_masking_max_percentage)\n",
    "        \n",
    "        num_freqs_to_mask = int(freq_percentage * all_freqs_num)\n",
    "        f0 = np.random.uniform(low=0.0, high=all_freqs_num - num_freqs_to_mask)\n",
    "        f0 = int(f0)\n",
    "        spec[:, f0:f0 + num_freqs_to_mask] = 0\n",
    "\n",
    "        time_percentage = random.uniform(0.0, time_masking_max_percentage)\n",
    "        \n",
    "        num_frames_to_mask = int(time_percentage * all_frames_num)\n",
    "        t0 = np.random.uniform(low=0.0, high=all_frames_num - num_frames_to_mask)\n",
    "        t0 = int(t0)\n",
    "        spec[t0:t0 + num_frames_to_mask, :] = 0\n",
    "    \n",
    "    return spec\n",
    "\n",
    "def get_specaugment_samples(X_train_bird,y_train_bird,num_specaugment_sample,rating_weights):\n",
    "    source_indices = torch.randint(0,len(y_train_bird),(num_specaugment_sample,))\n",
    "    specaugment_X_train = X_train_bird[source_indices]\n",
    "    specaugment_y_train = y_train_bird[source_indices]\n",
    "    \n",
    "    for i in range(num_specaugment_sample):\n",
    "        specaugment_X_train[i] = spec_augment(specaugment_X_train[i].squeeze()).view(1,X_train_bird.shape[2],X_train_bird.shape[3])\n",
    "\n",
    "    return specaugment_X_train, specaugment_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4271d43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs, batch_size, training_seq):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in (range(num_epochs)):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "        random.shuffle(training_seq)\n",
    "        \n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "            \n",
    "            #print(phase)\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            dataset_size =0\n",
    "        \n",
    "            for bird_idx in tqdm(training_seq):\n",
    "                X_bird, y_bird = get_spectograms_from_file(bird_idx) #get all training data for each bird\n",
    "                #split to train and val set \n",
    "                \n",
    "                train_index = int(TRAINING_VAL_SPLIT*len(y_bird)) #80:20 split for training and validation\n",
    "                if phase == 'train':\n",
    "                    #print('bird', idx2bird[bird_idx])\n",
    "                    #print('shape b4',X_bird.shape)\n",
    "                    X_train_bird = X_bird[0:train_index]\n",
    "                    y_train_bird = y_bird[0:train_index]\n",
    "                    \n",
    "                    bird = idx2bird[bird_idx] #get the rating weights for sampling\n",
    "                    rating_audio = bird_audio_rating_mapping[bird] #higher rating audio will have higher chance of being sampled\n",
    "                    rating_audio_tensor = torch.tensor(np.array(rating_audio))\n",
    "                    rating_weights = rating_audio_tensor[0:train_index]\n",
    "                    #print('shape 1',X_bird.shape)\n",
    "                    #upsampling and downsampling for each bird\n",
    "                    if len(y_train_bird) < TRAINING_THRESHOLD_UPSAMPLING:\n",
    "                        additional_num_samples = TRAINING_THRESHOLD_UPSAMPLING - len(y_train_bird) \n",
    "                        additional_X_train_bird, additional_y_train_bird = get_more_samples_raw(X_train_bird,y_train_bird,additional_num_samples,rating_weights)\n",
    "                        X_train_bird = torch.cat((X_train_bird,additional_X_train_bird),0)\n",
    "                        y_train_bird = torch.cat((y_train_bird,additional_y_train_bird),0)\n",
    "                        #print('upsampling completed for ',idx2bird[bird_idx])\n",
    "                    elif len(y_train_bird) > TRAINING_THRESHOLD_DOWNSAMPLING:\n",
    "                        X_train_bird, y_train_bird = get_down_samples(X_train_bird,y_train_bird,TRAINING_THRESHOLD_DOWNSAMPLING,rating_weights)\n",
    "                        #print('downsampling completed for ',idx2bird[bird_idx])\n",
    "                    \n",
    "                    #print('shape 2',X_bird.shape)\n",
    "                    #perform mixup for each bird\n",
    "                    if TRAINING_MIXUP_PERCENTAGE > 0:\n",
    "                        #generate additional sample\n",
    "                        num_mixup_sample = int(len(y_train_bird) * TRAINING_MIXUP_PERCENTAGE)\n",
    "                        mixup_X_train_bird, mixup_y_train_bird = get_mixup_samples(X_train_bird,y_train_bird,num_mixup_sample,rating_weights,TRAINING_VAL_SPLIT)\n",
    "                        #print('mixup completed for ',idx2bird[bird_idx])\n",
    "                    \n",
    "                    if TRAINING_SPECAUGMENT_PERCENTAGE >0:\n",
    "                        num_specaugment_sample = int(len(y_train_bird) * TRAINING_SPECAUGMENT_PERCENTAGE)\n",
    "                        specaugment_X_train_bird, specaugment_y_train_bird = get_specaugment_samples(X_train_bird,y_train_bird,num_specaugment_sample,rating_weights)\n",
    "                        #print('specaugment_X_train_bird.shape',specaugment_X_train_bird.shape)\n",
    "                        \n",
    "                    if TRAINING_MIXUP_PERCENTAGE > 0:\n",
    "                        #add the generated samples\n",
    "                        X_train_bird = torch.cat((X_train_bird,mixup_X_train_bird),0)\n",
    "                        y_train_bird = torch.cat((y_train_bird,mixup_y_train_bird),0)\n",
    "                    \n",
    "                    if TRAINING_SPECAUGMENT_PERCENTAGE > 0:\n",
    "                        #add the generated samples\n",
    "                        X_train_bird = torch.cat((X_train_bird,specaugment_X_train_bird),0)\n",
    "                        y_train_bird = torch.cat((y_train_bird,specaugment_y_train_bird),0)\n",
    "                        \n",
    "                    #e.g.     X_train_bird.shape = (640,1,128,216)\n",
    "                    dataset_size += len(y_train_bird)\n",
    "                else:\n",
    "                    X_train_bird = X_bird[train_index:]\n",
    "                    y_train_bird = y_bird[train_index:]\n",
    "                    dataset_size += (len(y_bird)-train_index-1)\n",
    "                \n",
    "                num_batch = -(-len(y_train_bird)//batch_size) #e.g.10\n",
    "                for batch in (range(num_batch)):\n",
    "                    X_train = X_train_bird[batch*batch_size : (batch+1)*batch_size]\n",
    "                    y_train = y_train_bird[batch*batch_size : (batch+1)*batch_size]\n",
    "                    X_train = X_train.to(device)\n",
    "                    y_train = y_train.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    \n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(X_train)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, y_train.type(torch.float))\n",
    "                    \n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                    \n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * X_train.size(0)\n",
    "                    _,ground_truth = torch.max(y_train, 1)\n",
    "                    running_corrects += torch.sum(preds == ground_truth)\n",
    "                    \n",
    "                    #clear memory\n",
    "                    del X_train\n",
    "                    del y_train\n",
    "                    gc.collect()\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                    \n",
    "            #statistics\n",
    "            epoch_loss = running_loss / dataset_size\n",
    "            epoch_acc = running_corrects.double() / dataset_size\n",
    "            \n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "            time_elapsed = time.time() - since\n",
    "            print(f'Time_elapsed {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "            \n",
    "             # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "            torch.save(model.state_dict(), './last_model_parameters.pt')\n",
    "        print()\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7495f4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL = 'resnet'\n",
    "MODEL = 'vit'\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "if MODEL == 'resnet':\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, len(all_birds))\n",
    "    model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    batch_size = 64\n",
    "    \n",
    "\n",
    "if MODEL == 'vit':\n",
    "    \n",
    "    efficient_transformer = Linformer(\n",
    "        dim=216,\n",
    "        seq_len=27649, # 128 * 216 + 1 cls token\n",
    "        depth=12,\n",
    "        heads=8,\n",
    "        k=64\n",
    "        )\n",
    "    \n",
    "    vit_model = ViT(\n",
    "        image_size=216,\n",
    "        patch_size=1,\n",
    "        num_classes=len(training_seq),\n",
    "        dim=216,\n",
    "        transformer=efficient_transformer,\n",
    "        channels=1\n",
    "        ).to(device)\n",
    "    \n",
    "    model = vit_model    \n",
    "    batch_size = 192    \n",
    "    \n",
    "#     LR = 0.001\n",
    "#     GAMMA = 0.7 #for learning rate scheduler \n",
    "#     scheduler = StepLR(optimizer, step_size=1, gamma=GAMMA)\n",
    "\n",
    "num_epochs = 50\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "#exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=1)\n",
    "\n",
    "#model.load_state_dict(torch.load('./last_model_parameters.pt'))\n",
    "best_model = train_model(model, criterion, optimizer, num_epochs, batch_size, training_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bd342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './best_model_parameters.pt')\n",
    "\n",
    "#model.load_state_dict(torch.load('./best_model_parameters.pt'))\n",
    "model.load_state_dict(torch.load('./last_model_parameters.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c499af63",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Audio_DIR = './test_soundscapes/'\n",
    "file_list = [f.split('.')[0] for f in sorted(os.listdir(Test_Audio_DIR))]\n",
    "\n",
    "print('Number of test soundscapes', len(file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a686919",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = {'row_id': [], 'target': []}\n",
    "threshold = 0.3\n",
    "model.eval() \n",
    "\n",
    "for file in file_list:\n",
    "    test_audio_file_path = test_audio_dir + file + '.ogg'\n",
    "    \n",
    "    chunk_duration = 5 #5sec chunk\n",
    "    duration = librosa.get_duration(filename=test_audio_file_path)\n",
    "    num_spectogram = int(duration/chunk_duration)\n",
    "    \n",
    "    chunks = [[] for i in range(num_spectogram)]\n",
    "\n",
    "    melspec_test = torch.tensor(get_spectograms(test_audio_file_path)).view(-1,1,128,216)\n",
    "    #X_test = torch.stack(melspec_test).to(device)\n",
    "    X_test = (melspec_test).to(device)\n",
    "    #print(X_test.shape)\n",
    "\n",
    "    outputs = model(X_test)\n",
    "    #print(outputs.shape)\n",
    "    outputs_test = torch.sigmoid(outputs)\n",
    "    #print(outputs_test.shape)\n",
    "    #print(scored_birds)\n",
    "\n",
    "    for idx, i in enumerate(range(len(chunks))):\n",
    "        chunk_end_time = (i + 1) * 5\n",
    "        for bird in scored_birds:\n",
    "            try:\n",
    "                score = outputs_test[idx][bird2idx[bird]]\n",
    "            except IndexError:\n",
    "                score = 0\n",
    "            \n",
    "            row_id = file + '_' + bird + '_' + str(chunk_end_time)\n",
    "            #print('score is ', score)\n",
    "            pred['row_id'].append(row_id)\n",
    "            pred['target'].append(True if score > threshold else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ac417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(pred, columns = ['row_id', 'target'])\n",
    "print(results)\n",
    "\n",
    "results.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e290e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
