{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9da5ffe",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0ef9c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# user_vig = True\n",
    "user_vig = False\n",
    "if user_vig:\n",
    "    sys.path.append(r\"C:\\users\\jaivignesh venugopal\\.pyenv\\pyenv-win\\versions\\3.6.8\\lib\\site-packages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61846c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os \n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import datasets, models, transforms\n",
    "import json\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "from IPython.display import Image\n",
    "import IPython.display as ipd\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "import random\n",
    "import gc\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "# for models\n",
    "from torch.optim.lr_scheduler import StepLR  \n",
    "from vit_pytorch.efficient import ViT\n",
    "from linformer import Linformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a639c526",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c4ce974",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_pt_DIR = './train_pt'\n",
    "Train_Metadata_DIR = './train_metadata.csv'\n",
    "Scored_Bird_DIR ='./scored_birds.json'\n",
    "Train_DIR = './train_audio/'\n",
    "Audio_Rating_Dir = \"./bird_audio_rating_mapping.pkl\"\n",
    "\n",
    "#read in metadata as df\n",
    "train_df = pd.read_csv(Train_Metadata_DIR)\n",
    "train_df.head()\n",
    "train_df['dir'] = Train_DIR+train_df['filename']\n",
    "#print(train_df['dir'])\n",
    "tqdm.pandas()\n",
    "#train_df['spectogram'] = train_df.progress_apply(lambda x: process_audio_to_spectogram(x['dir']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08321fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nnum_audio_files = train_df.shape[0]\\n\\nspectograms_list = []\\nfor i in tqdm(range(100)):\\n    current_bird = train_df.primary_label.loc[i]\\n    process_get_audio_chunks_images(train_df['dir'].iloc[i])\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "num_audio_files = train_df.shape[0]\n",
    "\n",
    "spectograms_list = []\n",
    "for i in tqdm(range(100)):\n",
    "    current_bird = train_df.primary_label.loc[i]\n",
    "    process_get_audio_chunks_images(train_df['dir'].iloc[i])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "863d51f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectograms_from_file(idx):\n",
    "    #get all the corresponding spectogram in np format\n",
    "    bird = idx2bird[idx]\n",
    "    pt_filepath = Train_pt_DIR+\"/\"+bird+\".pt\"\n",
    "    x_train = torch.load(pt_filepath).view(-1,1,128,216)\n",
    "    num_training_samples = x_train.shape[0]\n",
    "    #y_train is one hot encoded vector per training sample\n",
    "    y_train = torch.tensor(np.array([0]*len(all_birds))).view(1,-1)\n",
    "    y_train[0,idx] = 1\n",
    "    y_train = torch.cat([y_train]*num_training_samples)\n",
    "\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "311c201d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_training_spectograms_from_file(idx, n_spectograms, TRAINING_VAL_SPLIT):\n",
    "    #get n random spectogram (np format) of selected bird\n",
    "    bird = idx2bird[idx]\n",
    "    pt_filepath = Train_pt_DIR+\"/\"+bird+\".pt\"\n",
    "    x_train = torch.load(pt_filepath).view(-1,1,128,216) # to convert to N,C, H, W format\n",
    "    \n",
    "    train_index = int(TRAINING_VAL_SPLIT*len(x_train)) #80:20 split for training and validation\n",
    "    \n",
    "    indices = torch.randint(0,train_index,(n_spectograms,)) #only sample from training pool\n",
    "    selected_X_train = x_train[indices]\n",
    "    \n",
    "    y_train = torch.tensor(np.array([0]*len(all_birds))).view(1,-1)\n",
    "    y_train[0,idx] = 1\n",
    "    selected_y_train = torch.cat([y_train]*n_spectograms)\n",
    "    \n",
    "    return selected_X_train, selected_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a068e157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([41, 128, 216])\n",
      "torch.Size([325, 128, 216])\n"
     ]
    }
   ],
   "source": [
    "a = torch.load('./train_pt/hudgod.pt')\n",
    "print(a.shape)\n",
    "b = torch.load('./train_pt/redpha1.pt')\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fae65b4",
   "metadata": {},
   "source": [
    "### Noise Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1ffbbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_reduction(y, sr, plot=True, th=0.3):\n",
    "    from scipy.fft import fft, fftfreq, ifft\n",
    "    \n",
    "    SAMPLE_RATE = 1\n",
    "    DURATION = len(y) / SAMPLE_RATE\n",
    "    N = int(SAMPLE_RATE * DURATION)\n",
    "\n",
    "    yf = fft(y)\n",
    "    xf = fftfreq(N, 1 / SAMPLE_RATE)\n",
    "    \n",
    "    if plot:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(24, 8))\n",
    "        axes[0].plot(np.arange(len(y)), y)\n",
    "        axes[0].set_title('Before Time-Domain')\n",
    "        axes[1].plot(xf, np.abs(yf))\n",
    "        axes[1].set_title('Before Frequency-Domain')\n",
    "        plt.show()\n",
    "    \n",
    "    # Filtering Low-Pass\n",
    "    new_yf = yf.copy()\n",
    "    middle = len(y) / 2\n",
    "    new_yf[int(middle - len(y) * th):int(middle + len(y) * th)] = 0\n",
    "    new_y = ifft(new_yf)\n",
    "    new_y = new_y.real\n",
    "    \n",
    "    if plot:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(24, 8))\n",
    "        axes[0].plot(np.arange(len(y)), new_y)\n",
    "        axes[0].set_title('After Time-Domain')\n",
    "        axes[1].plot(xf, np.abs(new_yf))\n",
    "        axes[1].set_title('After Frequency-Domain')\n",
    "        plt.show()\n",
    "\n",
    "    return new_y, sr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6cb58e",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5f75b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of birds 152\n"
     ]
    }
   ],
   "source": [
    "all_birds = list(train_df.primary_label.dropna().unique())\n",
    "print('Total number of birds',len(all_birds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc1b1496",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for mapping of bird (str) to idx (int)\n",
    "bird2idx = {}\n",
    "for i, bird in enumerate(all_birds):\n",
    "    bird2idx[bird] = i\n",
    "    \n",
    "idx2bird = {}\n",
    "for _, (k, v) in enumerate(bird2idx.items()): \n",
    "    idx2bird[v] = k "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b9c7216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2bird[151]\n",
    "bird2idx['zebdov']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4e9738f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of birds 152\n",
      "Scored birds ['akiapo', 'aniani', 'apapan', 'barpet', 'crehon', 'elepai', 'ercfra', 'hawama', 'hawcre', 'hawgoo', 'hawhaw', 'hawpet1', 'houfin', 'iiwi', 'jabwar', 'maupar', 'omao', 'puaioh', 'skylar', 'warwhe1', 'yefcan']\n",
      "Number of scored birds training files \n",
      " akiapo      14\n",
      "aniani      12\n",
      "apapan      47\n",
      "barpet      15\n",
      "crehon       2\n",
      "elepai      14\n",
      "ercfra       6\n",
      "hawama      21\n",
      "hawcre      20\n",
      "hawgoo       9\n",
      "hawhaw       3\n",
      "hawpet1      3\n",
      "houfin     322\n",
      "iiwi        37\n",
      "jabwar      78\n",
      "maupar       1\n",
      "omao        21\n",
      "puaioh       3\n",
      "skylar     500\n",
      "warwhe1     71\n",
      "yefcan      67\n",
      "Name: primary_label, dtype: int64\n",
      "\n",
      "Number of training files per bird\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAD8CAYAAAC2PJlnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABLZUlEQVR4nO2dd5hcZdmH72dLNr130iihQ8AEpIsRkaYioNIEBEFFARFB7GAFUVBUULAAFixIx48q0ltCCQkQCCm09J5NsvX5/vi9hzMsm7KzMwGyz31de83MmXPeeQ+Xnl+ebu5OEARBEBRDxTu9gSAIguC9S4hIEARBUDQhIkEQBEHRhIgEQRAERRMiEgRBEBRNiEgQBEFQNCEiQRAEQdFsdCJiZlXv9B6CIAg6Cu0SETMbZWYvmNlVZvaimf3VzPYzs4fM7CUz2zX9PWJmT5nZw2a2Vbp2tZn9umCtW83scDO7zsxWmNkdZrbQzO4xswHpnJPNbKaZvWJm/zaz+81sXPr935rZY8BP2/VfJAiCIFhvSvGv9i2ATwInAk8ARwN7AR8DvgkcB+zt7o1mth/wY+DwVtYZA2zv7keYmQMzgJeAecD3gC8D17v7lQBm9kNgx4LrhwF7uHvT2jbbv39/HzVqVJG3GgRB0PGYOHHiAncf0Np3pRCRGe7+LICZTQHucXc3s2eBUUAv4AUz6wMYsLjwYjPrD9wCdAZ6mdlkoBl4HHgf8BfgbjN7BPiJmf0TWAEsB2oKluoFnA98u+UGzewU4BSAESNGMGHChBLcdhAEQcfAzGat6btSxETqCt43A7uZ2STgViQi9wKvAJOAa4H+ZnYP0Ak4ArgH+C7QAGwDbJb2NTatuT+yMnoB1wErkbD8A+iP3FdHp3O+09oG3f0Kdx/n7uPm1HcqwS0HQRAEUBpLpNrMXgAeRaJQARyLXFm9gFXptSuyLKqAm4C9gX7p/BeQILwfmIvE53NIlKqBWmAH5NrqC3QDDkzf7Q40AT2APYEHW26wpSUSBEEQlIZSZWdtgR7gU5BlcggSFEhuKmAacHE69mOgMr3vD1wKLAKWpmO1aW8NgKfj25G7qo5AYuPAVUioqpAwBUEQBBuIdomIu88EPgK8isTjL+n9Pek7R9bCi8AQ4Ix06ar09x8kHo8CtyMLo2c6pxLoguIow4D93f3y9N0DwPVp/c8AvZFQjVzXnl9fsqq4mw2CIAjeRqkskXpkCXwEWQxfMbOu6btGYCh6yD+fzu2bvuuV/sYDuyL31gokJoaC51ORW+tMMzs0Xbc7cF7a/0XAknT8JDPbouXmCmMilV17leSGgyAIgtIWG24F/AR4GAXIpyEhMGRVvJBeV6bfnQXslt5/B8VMAI4vWPM15O6qTOf9BVkfBwIz0znXpLUbganuPq3lxszsFDObYGYTBneqL83dBkEQBCUVkVeB11HtxnQU6Aal4VahrKsm4IZ0/NMoY6sReAQYgbK4QEKxCsVTZhb8RlckSn9N5zuybnZDcZPX17XJcGcFQRCUjvUWkVSdPrnl8YK4SDZntydySzWnz1OQGNSj+MeL6fjngIHAHCQuDjwJnEBuvYBiKqBgemN6X4esDyPPMOsHzG5t7+HOCoIgKA9ttkTWJCbIMvgYetD/F/g+EoZN0EO/Cbm8zkBZV59HgfU6cqHYrmC9LDNrJ2BZWjtjPLAlKlzM3FcrWUOdSLizgiAIykNbRaQSxT22MLM7zayLmZ2M6j7qkHBUILfTaaiuow/KspoE/B0YALyMrJMD0meQyHQueF9Fnm31BVRQmFkdc9K604HfosB6JXC7mW3exnsKgiAIiqStIjIa+DPqa7UF6m11NIpJnJbWq0DZVy8CDyErI6v1ODN9Pxe5u4Yg4XghnTcMFRwacDdK+wX4Xbp+HoqRXAr8AAXev42sllnAKnd/ueWmo2I9CIKgPLRVRGYAzyExuRlZAQCTgV+hIsFmYBBKwx2NAuSrgYORhdGAKtKdXEw2RS6rxemaClQ4uE36fgZyhQ0ATiavdt8cpQF3QmnBj7e26XBnBUEQlIe2ikjWJ2sGsgKqUPfdB4E3UFzCgK2RS2trJCLV6c+QeExElsUwZIkY8BTwx7SnLA14ABKe7dNnR1bJDsA+yN3VhIL5AyhNG5cgCIJgPSk2xbew6WINsjSGocpxgAUo/lGB4hd1SBia0ne7p2ua0+vtKAX4MCQUVSiTawWyeP6argfFV/4K3I/SiGegYH418Ni6Nh4pvkEQBKXD3H3dZ6GsLNSZ95D0ehXQHVkF+yFr4BYkFB8F5iOXEyjo3YAEZwbK5KoAFqL4iaGuvIcjMViIhGFgWm81cleRzq1FKcN9kBBlYjjJ3ces7T5qhoz2Icf/AoCZFxy8XvceBEHQkTGzie4+rtXv1ldEChYbBdzq7tunz19DVshxyEU1HwXAd0MiU4FE5J/kgfRdkRhMQnGRoSgVeD6KczyVji1GFspyZIF0T9s4A/glEpBGFGwfAixx97e16W3RxXfsrFlrbI0fBEEQtGBtItJmd5a7z8wEJH3+GfAL9KB/BonEDqiCfRESEEeisjcKoi9Pl49AtSEVKNNrFfAjFPfoh6yUmWnNrEiRdP0nyAscN0MxmC7r2v/rS1Yx6tzbGHXubW267yAIguDtFFNs2M3MbjOzZ8xsspl9GtgDCcIYVDXeAxUJDs4uQ5bGiyhLK5tIOBe5pLZJn0ei7KsL0t5eRJlc3ZCbK6tY3x3FTSqBq4FvoFhL1n/rLUTFehAEQXkoJpvpAOANdz8YwMyy7rzTUaxiPxSvAFki/ZDFMAlZIdNRSq4Dw5EQLEcCsgS5sSqQa+wW5PqqRxXqVShGMpC8LcrH07E+Bb/7FloOpYpYSBAEQWkoJjvrWeDDZnahme2NLIVpwEmo1uOjwP+RxytWoWD6GOSemowe9s2ocv0l1HhxMoqtVCHLZR7wofSbf05rOgqy/xRlay1HItUfmAD8vIj7CYIgCIqkzYF1ADPrCxyEXE9Poj5YT6Dxt08i8RiPMrKqkFtqKrJSDLmx+qbvlqKak02RSPRFo3V/gircv46C5gtQoH0UEpepSIBWp+sqgUPcvdWCw4zC7CyIDK0gCIJ1sbbAepvdWWY2FFjk7n8xsyXA2Sig/Ts0ZfBDyI0FeYHgMOSC6pSOPZe+PwDFMaYBdwBHofTebyEBOhO5v3qjWMtw8ur0nZG1smnBvZxAK1Xr4c4KgiAoD8W4s3YAHjezp4HvAT9DD/MrkFjcg3phNae/icilVYncVquADwB7petqgXGo0BBUnf5zJBb1KFurK2p7kgXWJwJfQi1SqsjFMHqaBEEQbEDabIm4+x3IagDerBtZ7e6D0ufxqBkjyHW1GhUiLiEfTLUXqvUYAIxFjRqHIoE6DA22akBNHv+KKt5/g7Kw6pBQjUJWy2fRxMOewMfMbJa7X7Km/WcpvhlhlQRBEBRPKSYbDgNGmFnWluQsFESvQCLVCDyNHvLNyCL5C7AnEpPeKO13h3T+d9HskE7ILfZUOn4IaoMCEqfjUPzkeuTecmBoawISKb5BEATloWgRaTGcqh6oNrPnUVV5P2SNNKDW7vOBU9HDvwkF5U8lH317CwrS16OW7k+h7KuzUAW7pTUt+3nk8mpC1kg29GpNe31LF9+ZFxz85l8QBEFQPKXqepuleDWj+MUE4Fj0gL8RVbL/DD385wAXAvuSB+DrUQFiA7BLOlaB2ssvJW8n3zOdeyxyZ52GMrd6Igsni5mskZbuLAiXVhAEQbG0151VCZyDBKACBch7oBYnO6CK9cGo2rwPEolewKGo+DDrunsgSuvNKs4zUXoC+GA63gMJSCWqaL8dBei3RdlhaxSQcGcFQRCUh/ZaIqORy2kbZBkcDjyavluCXFl7oDYlTl4jUpOufSodvxel73YBfo8sjeHks0ocOBe1UjkM2B+YkvZ/DoqjVABdzOzMlnGRSPENgiAoD+21RLJJh3VprQtRY8TNUKquo3jIr9P7lSgQ34zqRg5AwfJNUSNGQ3Umg8nniixOv/V14AgkOKuQq6sZiUs3FBNpXFtmVhAEQVBa2muJFA6nOg9VrH80fZ6HmjIOBr6DROEe4MOocLA3cm31AP6D0n37ARcjcfo06gTcCwlRLYqPHJ6OgwoR65G7y8gD72/B3a9AdSzUDBntrXXwDeskCIKg7RTV9gRaHVK1FLmvDMUnvowe3E3A31AabxVyWTWh9u6k9ytQC5N+SHReQcWFK1B/rL5pzcp03VyU4XVz+twd9e3q7u5v6+Qb80SCIAiKp6TzRFri7jORYGyNHuSzUSD9PORuMuBoJCBZU8brUMzE0ZjbOcjVNRiJwqD03VIkHFn2Vk1aozea6T4VCUwNUNWagARBEATlo2h3VhKPbDhVL2Q1LEKicBp5W/d/o8ysPZBozQc+iQZZDU5r9ErndkaWSY+07m9RZXslEpRm5PZagNxi3VBMZkugs5n9wd1PWtu+W0vxzQiXVhAEQdso2p31lkXMaoDXkTuqHs0X+QtwEYqN9EICkLmxKsitlMkosN6F3FrJpiE+j+aMVCO3Vi2Ks4AslxryADzAXHfPBmG1SssuvoWEiARBELydknbxTQuOomDOurvXmdmtyCLYDvW8OgZlVlUj0ViNRKQ7cml9AzgeWS9ZG/j/oaLEvwE93X07M1uEihUrkMsM1OCxIv1OQ1q3Eyl43sp+I8U3CIKgDLQnO6u3mU0in1rYCT3MlyHhALmblqEHfk9Uwd6UrnkCOB+1NVmBxKU/agNfC/Qys2eRFTPK3Tcxs6uQ8BwIXIZE6++oD9dQVGOyVsKdFQRBUDqKDayPRrGJ8aguZAwqNtwDzVLvSe526p9+ZzGyTipRHOMylJpbjWIchjKyeiBBqCfvh1VjZneQt4sHNV4EzSAZmdY6obXNRsV6EARBeSjWEtkDBbr7IUvgM6hy/O/ITVWPxGQOKiqsQ1lUt6Tr7wMuQTGPR9HEwwZkgfRP5yxGfbRqkbAcgdxVR6bv70UWzUvp+5Eoa+tthDsrCIKgPLQnxbcrcBNwjLs/gyyK45EVshg94Lum36hFwnFVuvZgVIG+Etg1fW8oUH4xip8MpKBBo7svR2LUjOpSbk3XOMr+AjjWzC5qxz0FQRAEbaBYS+RhFAOZDexlZnPI56tvilxZRl402AcJwjGotiNzh/VBLqvs2peQayyLqXwdFTAebWaXoZ5ZFcCf03U/Qa6xGiRes9397JabXZ+K9YywUoIgCNafYkXkJZS6OxBZDsegB/9i8imGWfB8q/T+4+n7LZAQLEOWxXRkVTjK2toRWSgNyDV2KRKMz6JZ7EOAH6TfqETdgs9HExC3M7Mh7j67cLPhzgqCICgP7XFnLXH37VBDxa7AH1EBYEP6ewXVilSm36lI7x9M11+M2pZsgeInzUhAbknve6DakHPTtX8B7kSur+WoCWMdioN8Il2zknweSRAEQVBmirJECqvV3X0J6cFtZlcjkVgBTEQP/gokKMOQRfEXNAekC/BLlK47C/gKcBdwIrJIqpEL7MdIoI5C1e6rUSPHvyIhGohSfRuRkKyVtaX4ZoSlEgRBsH6UarJhIZsUvO+dXrN032ygFCiekaX0bgv8H4qjZG1NQEH3zZEQdUZZX1XAp5B7rIa8MSPIlfYRZOG8ScuYSPtuLwiCIMgoh4hMJ58H8hJKvc2KMz6N4hn9kLDchVxRzyBRuRxZMvun85ejDLBTkJUxgnyM7kdRC/lp6dwKYJG7f6nlhiImEgRBUB6KFhEz+ypyPQH83t1/gZoqriRvz16LrINm9JC/Gbm2HGVjbY4Eph+yULog66NnWrcO1Yc4miGyAlktjgLqmeUyBwXtM4tkjYQ7KwiCoHQUFVg3s7EoW+r9aJ76yWa2MxKVH6V1B6J2JEsLfqeCPP3360gwlqNYydbIgjkTxT1AQlSVruuB2qusRvGSLyIxyVqp9Cef0f4WomI9CIKgPBRriewF3ODutQBmdj2wN4pTnIQsj07Ai8iqaEAP/lPRTPatUTv4pejhPwAJQTNycT2HBOh0FHT/L8rG2pF8zsg+wMtoFG8WUK80s03dfUbhZsOdFQRBUB5KHRPZD7mZbkQZWFXIcuiMHv5Dkag4qgHpjgoWX0Yiswdyd3VJ630ZDagC1aV0R+6y3ijdtxMSkGpk3VQgC+cLa9pguLOCIAhKR7F1Ig8Ah5rZ1mY2BQXH90WWwn0oiwrgKfI27iuBX6MsqSXI9dQJeDqdOwxZLIvSd3XI3XVH+r4/irFMRy6sySgG8goal7sa+KG7v01Awp0VBEFQHoqtE3kytWW/CWVf/QI4HHgcpfhmw6VArq9VqC3855GLKmt3MgdlYjUjITB3397MpgHd3L3ZzG5GLrIrUWX8ziit9yPIotkciUsV0M/MumVutoxwZwVBEJSHoivW3f1i9CCfgeITvZEYvA+5mkB9tP5FeoCjwsEe5DNGnkJZVTWoo2+jmU0HhqN5JYej+EcT8D1UV9KM+m/dnP6WIsulChVAliNtOQiCIGiFUjxwR6NphPem94cDt6O6j1oU5zgQWQ+GRCCbpT4KWSCDUDbXNcDR5JbMKuBa5LbaEQXlj0eC8ikkXqegme57Ab9096Vr2+z6xEQg4iJBEATrQ7tmrKcxuXcBhwI3oAd+A/AGin1kY2vr02vW/iRrwFiFguiOBOJsZKnUIOF4FaUEZ9MTt07nL0DWR2ckTp3I031/7O6XrGnP48aN8wkTJhR9z0EQBB2Ntc1Yb08Dxow6d5+C6kNOQRlVvwTuR+LxOrJIQEJQh4oGG5EILCQfNtWPfAbJn9x9UxR4z/b5anq9FsVfngI+hwL1AH9uTUDM7BQzm2BmE+bPn1+CWw6CIAhgPd1ZyeK4HU0h3AO1eP8TqjIfbWa7ophGHbIiOiNrYQlK3x2Zju+ILInnUcru3qhi/QDk0vodsBOwDXCMme2PhMVQzCXrwfUJNAr3JtRGpQeyRO5b172EOysIgqB0tMUS2QL4OXIpbY1iF0egDKtvAi+guen/QBbIJ1Gm1naoNqQLcnWB4h3d0+9Xo+B8A0rjHY6KD6uRyC1EAtEXiQmo4+/eSKiGkNrNu/tNrW08UnyDIAjKQ1sC6zPc/VmAVBtyj7vPNLMPAtcji2J3lJ3VBZiJguX9UNV5FXJh1QMXoWFTjuIkf0MtVPZCMROQVbM8rWHIEtofWSTT07mg2Eo/bcvOXJM7i0jxDYIgKDltEZG6gvfNBZ+b0zo/QBlaz6L2JoayqH6K6kK6IAuD9LlbOqcP8FXk7soGUfVK6/8YWTq3IhdWNj3xaRRXOQZZKBmr1nUT4c4KgiAoHaUIrGf0QkF0kGBUoYf8k6iu4xGUydUJ+D55MLwaCc/K9N0h5K1NLkeusEpUkV6X1j4c+B8SpQrUDr4Opf++jXBnBUEQlIdSFub9FLgaPfA7o0D5oeRpv1l62GoU59gEpQBXo9kglcB1KLNrH1RIOBi4CrmsapGLbFvkCstmloDqU0B9u95GuLOCIAjKw3qJSOE4XDM7G3jS3a8zs0uAMch6uBd4GD3YRyJRuANZDEPSUs+hqvNN0CTDjyKXVhYw3wRlZz2RjjUiK2MJ6uo7JK3/GHmn4BokRl3RPPYgCIJgA1GMJfIAKgy8FD3Yd0BZW8NRBtcfUPxiNrIW9kFxjwqUuvufdN3maT1HFkZnVMH+ZDqvGVkfg1E68ENILLZAgtYHZWe9hFKHK4HTzez/3P3lNW1+fWMiGWG1BEEQrJk2V6ybWTWKceyEBGEPFBj/MXl1elZJXp1eF6IsqwaUzrsFEokZwJao19aHkcXRPV1XR97efTGyYvZBqcRZYGM1Eq/KdN7N7v7xte0/KtaDIAjaRkkr1t09E4ITgImo99VQFPBeheIXN6G5HkvS6yPI4mhAQ6RWIoEYjESne1qnElW1g7K03kBV6tl3htxWS1Fa70AUc7kfiVXjGv4DRMV6EARBGSg2sP4A8DU0WGp/lIW1Mn3XndzN1RM1Z1yJBGsKMBa5oN6Xzr0Zuad6IZHZKq3zOxQj2QbVjmTpwb9090vM7MvI+jkWCVQ9+Wz2NRLurCAIgtLRnqFUQ5CFsClyPdUiUVhMbmVUkLdub0QCUoncWVn1+lgUH+mChOCEdPxbwMHkxYvZ8Z+b2cz0Xfe0TgVyoe3U2mYjxTcIgqA8tLeL717A3agNyh3IYliIYhoPoXqOJUg4QG6wHVCzxYuRpbEaBeFHIVfWrkiU6tP5Vaha/Rxgfjq3ByoybEDtV65N16wG9nb3l1rsszDFd+ysWbOKvucgCIKOxtpiIu2tE3kNPeh/gkSgGcUwtkXz1ptQ0WADimOMQlbKJSi2UQtMQLENR0H2F9I6huInq9P31cjaGJnOrUBpwj9Lx5vT7wxB7rJWCXdWEARB6WiTO8vMRpnZ5BaHRwMXolhGZ2R59ECZWsvRw/1xJBivoTYmx5G3hx+FrIrVyPp4Lu2rEQXWDTVxvBAF7huRUFUAu6AWK5AH7rOxvG8S7qwgCILyUIqK9Rnu/nRqFz8fxTeyTKrhqJZjFxQ/6YVEoHc6dxMkNN1Qy5QXUPzk4HT+Aahu5GkUQO+CRKg6/fZMVJdCOudGd3+w5QajYj0IgqA8FBNYrzSzK1Mn32uAejM7Gc1Sb0QV5I6KEZ8FTkLWwXAUbH8NOD+dV4+skG7IZfUd5AJbhgRnAnJ7bYJiLKQ1uqT3W5N3/Z2LWtEHQRAEG4hiLJHRwFHufrKZ3Yqys6539yvN7GtojsgoZBmMSZ8Xk6foDkbCsRyl/nZDwvEi8Ou0XnfkytoWtT3ZO60B8G9Ud/IZJFZd0xorkWD9am2bb2tMBCIuEgRBsCbalJ2VzVR399Hp88+A01CMYgiyRHogV1YdskBWoXki25EHzGtQoL1n+uzpbznKxPo0slJuRU0cl6N4RyWyUFYh4ZiCLJFeSIj+5O4nr+0eomI9CIKgbZR6xnrhXJEBwGT0cN8Dja9dimZ9XIdEo4K8kNBQCjDkdSKrgfOAG9O570fjcw0VMtYi0emFrI5m1Esrm2r4EhKVl5FL7G1ExXoQBEF5aG9gfTbwcfRwPxW4AsUrFrv7sWZ2Dqoqr0fB8GWocWI24dDSHvZHLqxu6TUzjyqQQGWWyjxkvfwHWSAHorjI6yjm8sK6NlyMOwvCpRUEQdAa7R1KtQC1J7kD+BzqmWVADzP7CiocrCQXjj8iq6ISiYin95uRD5iqR5ZFXfq+Kl0zD/XL6gF8Cs0rWYaEZwRKL25qbZOR4hsEQVAe2mSJFM4VSfwNWIQe3q8iN1R/4D40K2T79F0WBzmLfJzuI+Qpvk1obno2aOo81OZkUTqnGolGXdrHQDP7DxKVzEppACaZWaW7v0VMIsU3CIKgPLTXnbUDcBEShq4oI2s2yqYajh76metqJXroz0S9s95AD/+pwO5IfBy4DfgucotVIHHYH7geWRtvpN/eO63tqLBxEfAl1IblbbUiGeHOCoIgKB1Fu7NSptYvUTFgVyQOx6GGiY6si/nIAumaPtcDf0pLfAqJzwjkFjsJCcYOSEAa0YTD55FFU5uO9zGzGhSgr0UV7oYC+v9srdiwFO6sYoQnCIJgY6e9lsgWqA7kRBTUHoDiG/uh4sO+KJZxavrcjOaLgHpeOWon3xNZKZ3Ta2bB7JzW/S7qt/VtJHxfRNlYH0QxElCgPXv/FsKdFQRBUB7aKyIz3P1ZADN7FDjf3WvNbDdkGfRB1sPV5HGLZUg0vosskzrUb2smeT+tqoK/rdN1XdLfTCQ8r6E4TBZHqQJazWMOgiAIykN7RaSwZqS54PPjwJdRHKQHcmVVpN97FlkNL6Lq9GGoH1Y38uFShmpNatDY3KvSek8C30Q1KGNQseFS5AJrYg11IoUUGxMpJCyZIAgCUYoGjK2xD6r3AInLMuTqqkTz1A9EcZKLkFurCtWTdAfuQqnCV6Xrr0fi0ISq3u9EYrMKxUoqyGMwl7e2GXe/AtWwqGI9RCAIgqAktLdO5G2Y2S7AR8jnrYPEowk97G9Jx0ajGEcjsjp+kI6PQ7Uny4FXUHB9KbJOFqEYyZ0oiP9KWncGytC6ew17ior1IAiCMtBeS6TSzK5ELU9eR+m530cxj1oUJL8FeAr4Hgqy35CunYLallShho37IndY1qHX0veL0lqdkFXTBVk6/0LZX71Qr637UZrwWimFOysj3FpBEHR02muJjAZ+4+7boeD44cAxyCI4AwnBWJRNBZojkk0d3JzcTeVohoihYHwFqjepQnPTByLLZjiKoXRFBYkNac07kLhYa5uMivUgCILyUIrsrKfT+4lIGCqAHdHI3Gnp2I9QQLwa+AuwJ7Ia/oIskh8gMTgUBc2rUQylIb1/CYnKvmn9h1C9yZXISumZ9vAPM7vf3T9YuMlI8Q2CICgPpczOyuap1wM3IzdWL2QdfDa9NgBfQ1bLIOBI8jYojjoCL0OzQ0amNTul738EfACl9fYHvpp+dzoqOPwkcn19fG0bLqU7C8KlFQRBx6bUgfWlSAAedvctkaXQhILgWZuT/VDsZBowHvgp8Bvy2ehdUYzkn8iFBSosBAlRPRKffunzMFSk2IxcYVmA/k3CnRUEQVAeypHiezxwt5l1I8+8mpS+q3X3VWZ2B3IvfQ/FPBy5rZYjYeiEguWr03X/LvyBNNP9P8jCaUBxlwqg3t3PaLmhcGcFQRCUh6ItEXef6e7bF3z+Gart+Aea9zEd1YB0QV19X0NWBMAu6bfHo4LCbAriqeTZWW+QzxK5AvXkqgUqzOxVNFN9abp+cFrvC8XeTxAEQdB2ymGJjEbWSE/gCPKA+EPA9WY2Frmj/pi+OxEF5T+FrJFbURv5vwJnI8vkyfT9AlQF3zutvQq5zIajmMjPgWvWtrlSx0QKCQsnCIKORptmrK9zMXX2vdfdN03z149E80CWIFF5A7gU2BK1LdkeCdnjyCW1ElWtd0JuqkzkrkTC0q/gu5XkM9qXoPYqzcDR7n7dmvYYM9aDIAjaRqlnrK+LrImiAZel99ej7r13AXsBBwAHu3tXVH3eCbgQubKuQWJwCgrKNwGHIZfV68j1lVXDZ8H4zsAsJDpvMzOiYj0IgqA8tNmdZWbHoTRdRwHzfwHfQkJQi+IYoDjIn5DVcAiyGq5FcZJhwEwzW41cU9PSa2dkcVQAv077m5PWWI1mjzyP3GD1qJYkow5odPdVrIVyurMgXFpBEHQs2mSJmNl2qFK8K/AMCpDvntapRBZC9mD/WjqvGrmo3g8MRfUfK9L5vVHA/UrUlHExcllBPlOkGwqeZ9dshWIjz6Xfy0bvdiYP3L+FSPENgiAoD22KiZjZaeghfirql9UTOBkVFQ5Brd2npO8fRBXot6MphBegxoy7ITfUAShmcizqhfVEOu/XqNodJBI1wOeAo5BwnY2E5xA0jvdx1LRxLhKhHdw9c3Nl+y5M8R07a9as9b7nIAiCjs7aYiLFZmfNcvdHU/D8oyhgvgyl3I5A1epVwFnpeAVq9d6M3FJnA79FAfZOwIfI60SaUHfe4em3mlFPrvehQkXSuaPc3czs38CuKNBO+v2Za9p4uLOCIAhKR1sD6/8FDiIvAuyCOvOent43oXYmz6dzdkEisQBZGHOR1fI91IG3AbmjfpbW6wHsj4Lo2f4WI7HZAfXQakxr/9bMjLyu5MX0+jbTKtxZQRAE5aHNKb5mdhbqYzUVicJIFPsYhtxNm6C27Fuhh/6hSFxuQn2tKpB1UpOWrEaupkvIiwu7ofjG95E1A7J2BqKYy0zUGmUOanXSGTWD3GwNew53VhAEQZGUOsX338A0dx/j7vujNN5aZFX0QvGKseiB/3EkCs0oHtKILI8X0vmd0+dzUHxlJqp0b0bicgQSqq5IlPqn9bqmvdxNbnkMN7N/FXE/QRAEQZG0OSbi7jNRkWBGJ+Dv6IE/ETga1YTMBv6GAt8jkAWRDZfantwSaUZDq7ZCcY2dkbBMBLZBgvE6cnE1oMr1K9M5e6Lge2fUOfj9ZjbE3We32POb43Frhoz2csZEIOIiQRB0HNpdsW5muwHfQW6txWh+SG8kCD2Q6+oFlJVViR7+WUylNp37JIqfLEOxjWyQ1XdRWvBq5CobgyyUzFJpQBldg9JaTwMXufvNLfYY7qwgCIIiKXfF+kQU9K4gny/yOxTwrkAikbU3aUQ9s/6O3FCVSDi+hIRhBrJEXkBpvT2QUMxA1kxVuuZVFJifD/wC1YzciyyXclThB0EQBK3Q7gaM7t5gZi+hwHl/8tTdZenza8hq6AE8iyyOqSj4PhS5se5FFsrWyKJYgKyR6rTHBUg4tkGpv8OB3yN31lfT72xOPldkjZQ7xTcjXFpBEHQESvWv9gdQhfr9wNXIFdUZCcAw1B+rEgnJVihja5/0XSWyNhrS+66oCr4LipU4EpZJSCxAgfgDkVhlFk8FsLylKwsixTcIgqBclKSLr5l9CFWm90bZVG8AN6L27GeiuemZWFSjYPgqoG96PR0FvheggHtP5Bp7HrnCmlC68BDUFuV55N6qRxXz/0hbWeHuvVvZX8REgiAIiqQcFetvwd3vQeKA6v/YDrmbhqBeW57+bkPtSl5DgtIXWRkTyHtgzUQxlnqUlbUdirHsh1KIHfgyCrrXIgHJ6ktsXXvdUO4sCJdWEAQbP+UKQh+DBGIJCqQvTMeHpGOrUPC8DrmobkDZXBPRQKt6VHC4N+qjdRxqFX8fskquBT6AJiNeiMRkGbDYzDZtuZl3yp21ocQqCILgnaIckw1BFsNC9HA/DKXgOkrR7YxqRf6ZvpuLLInOwLg0P30KskAqgW+k1xNRj6wq5O6ajKYonoLiKIasm9Eom+tNYsZ6EARBeSiJJWJmN5rZxPTwr0KjbT+DxGRvZGU4siBWIyvju+ny+5F7aibQzcxqUZbWKpSRdVna557IcmlCAnUWEpc+5BXz33b3O0txT0EQBMG6KZUlcqK7LzKzTZAV4OjBfwbqfzUofd4hnW8oFfg0FCPZDTVyHIbSfl9B1kYXVKHejCyS01HwfiASD0u/9QpK8e1nZt3cPZuuCGz4ivXWCOsnCIKNkVKJyHfN7PNIKJqQS6kZeBlZHcuQy2kQcmWBCgwNeAgF2sch62Mysly6ogaLvwe+iVrJV6drFyI32DxUaJiteyrwm5abC3dWEARBeWiXOyu5saYCnwcWu3sNeph/Ja19NQqWZ32vnkyXvo7G6joqKpyfzlmJXFMPkVe774PE5hokNqBg/NUo3Xcv1NHXgFfdfWl77ikIgiBYf9priZyIYh5nAHua2e3o4b9t+n4zJCrnoUmI2SySQcjquCdd/0lkZWRjbj+Y1umGXFxTkHUzMK3bCFyP3FuPp/N2WJ/72ZApvq0RVlAQBBsT7Q2snw78AGVNdSLPwtoMubMqUWPG/VAhYTUSgE4o8D4WPfhHIPHogawPBxYhwemZznsfcouBxGZHlAr8CLmba7vWNvluqliPtN8gCDYmirZEzGxfJA67IQvhBVSz8TdkGTSjh/4q1POqd7r0ayjjajJq6f5NVDsyHY3abQDuQunAm6N2J32Q8HRK6xpybb2ChGw1Ep4urbWCj5hIEARBeWiPO+vjyBp4BAW5a4Bvk9drVKAHfi15Ki5oNG4zEolz0vnzUJbWSmSRHIHiJ/cAO6V9LgFWoNiJo3klm6f1nwHej0RmFzRbpFXeaXcWhEsrCIKNh6LcWWa2HXroP44e3JkYTSVv8Z65rYairrvD0jkDgauQ0IxEovABJCYPo4ysRiQye6Tvm1Ew/l6UtVUB/BRZIJ1RgH2NTcDeTe4skEvrnRayIAiCUlCsJTIe+Ke7fwvAzEYB08iHTmWDpx4CDkjXZOm7WwMfQ+6vbYHlqKFiJhiLUVfgLNjehIRiR9SM0ZE4bYKskAHIIslShye23Gy4s4IgCMpDSSrW08jcJSje8QaKb/QktzCWo2yqHYHu6bKsKPEW5IoCtYmvQ7GRVch9VYkskZ8jYVmd1nww7X8luRi+imIyQRAEwQagqFbwyZ11A7C7uy80s77IRXUveTuSQShW0hNZEq+gGSATkNUwD7m65iIh2Cy9rkDuqVUo1tEbWSzPpHWGI5fYpPQ7q9Kx7sCP3P3ba9t7zZDRPuT4X7T5nstJWEZBELybKXkreHefYmY/Au4zsyY0POo01BtrE2RNvIYe7i+iFN55KK23Ob3/NvAnVHG+c1o6E5veyK0Fyvi6hnzIVRdUCV+f1s2GVq0GTkjrtvwPEO6sIAiCMlB0dpa7X42qxt/EzJ5A8YmHUWFhI0rjPRkJxTgUIO8P/Dpdtj2Kp+yCLJHG9Nc9rZU1asxmrDeh4HrfdLwZpRQ3oBTf7u6+otj7CoIgCNafdYqImZ0N1Ln7pWZ2CTDG3ceb2XjgJFQLsguyEO5CInEmyt6qQP2suqBiw8eAg1HA/Cw0K6QTCobvkq5dnq5bClyOxOQ7KIayNQrCT0QjdqtRgeGjwBvu3mqxYSHvhhTf9SGspSAI3gusjyXyAHrgX4osiRozq0btSu4H/pU6+Faiuo46YN+CtfuTz0E/iLxqfQwSEAM+lM4dhoZYbYf6YV2ALA3SeauQ5TKSvPDwTlTpPtTMdnL3p1veQMsuvutxz+84hUIXghIEwbuV9RGRicBYM8vmnj+JxGRvVC3+qRRzqEKTC/+GmiaCrI/5qO/VShQTuRQFxg9HLqingI+gGMjTKF7SDbmtLkSzRroBW6TfaAaeRUIzHRUdDkFxlFNJsY9CIiYSBEFQHtYpIu7eYGYzUND6YZQV9UH0UF+F0np3QQOossrx96XLF6HW7JegwPfFSEymoWysalSR/gYSh2FobkhWsDgIWS2r0zU7APPdfU8zW5LWuB9ZMo6GYa2V94o7qzVC/IIgeLexvnUiDyCxuD+9/wKyIHqizKilyG3VE7gb+E+6bgRwEbJIegGbIvHJ+mA5ioOsTq/dgS2R6wokSt1QIH0JErD+qW9X5/T3cfJaki+2tvl3W8V6EATBxsL6Zmc9AHwLeMTda81sNfCAuz9jZk+h6vP5yDJ5Gfh0uu55VEDYF4nEJig1N4tngGIcVcgaeRDYH7m2eiM31wIU83h/Oq8SBe0fRW6zbmmdSuR2q3T3psLNhzsrCIKgPKyXJeLu97h7dTZ21t23dPeL0/sT3H1L4BhkLXwHFRQ2ArOQlWLISnkOiccQ5NaajsRjQfq7G8VJGlFMZDyKn3RDwf0HkPWyArm26lEhYl1adxNg92L/YwRBEARtoyTjcc2sG8qqGoKEYVckEmOQCMxFAfnDkJVRgTK2RqA4yRnI8jgUichDyAoBxU1qkaisLPjZhcjNdT8SmVpgsrs/2HJ/74YZ66UirKggCN5NlGrG+gFIKKYiK2QP8mmDB6HA+kHp+2okFOehOpFzkBWxEBUkdkaB8u4oM2wJmkdyEbJoGtNvVqL2859Akw8rgD5mVuXu2TlAuLOCIAjKRUkaMKKU271Rz6vfIYvE0MP9YnKx6kMe1zg2HcuC4i+lz3XI7eVImH6CsrQqya2Yo5Hrapq7Z+3nHaUS/7RE9xQEQRCsg3ZZIqkF/P+hgHgdytD6MbIQpgB7oiD6k8iy6Eneyn0Emh0yGAnElshKMZQyDBKKLLYyIK0/D1XE3whsYmYXkrdDaXL3r65tz+/lFN+MsKSCIHi3UApLZDTwT1T8dzNqbWIoxrEQuA8JRe/0e1nFeBZMJ53fhESkAmV5GcrcuhsJyGsoVjIECUg2Z+Rz6f1coMrM+rfcYKT4BkEQlIdSxERmoAd/LXqQN6e/28irx7NBVTNQMLw/ms3+WzRj5H5UwNiE3Fq9kOWyMq3dhMRji7T2Y8DvgV+g9N9a5AIb0doGIyYSBEFQHkohInXufoeZrULxj+6oHXstckV9BBUm9kdCsBq5r8ah5o0O3Ozuzamt/GhUa9IfWRqe9tmQzl+MxOKYtFYVapfyT/Ipimsk3FlBEASlo1SB9ZZUood8NQq6d0Ui8Bqq7QC1QzksvV9hZi+m/VSgdimVyHJZgWIoXVD7+M3RnJIXkHXTDVkuGZu13MzG5s56r4tgEAQbD6VK8S1kTHqdh2IZFciC6IYEIKMRpfCOB85H6cBzUHHiFFShbsBXkWWzORp89SISit8iy2MgEpQ70rrTW24o3FlBEATloV2WiLvPdPftCw79DbWBb3T3HVGAfBoSq25oBvorKMbRjJovgqyO+5EYrES1H6AYyOlIWJqRxbE8rXsXSiluQm1QnmjPvQRBEARtp1QV619A7qb/kFxSZrY/cmNth1qbPIJSfkGi0Re5uGqR2+t4NKO9BsVQ3odcWbuhvluOLJOV6ZqGtL6jFGBDMZe3sTFVrLdGWFZBELxTmHtpZjSZWVb/8QxquvgQ6mNlKNW3LxKtemRZrETWSQ8kHMuRG2sccoUNJE8Jbkg/04jE6lUUF6lIx6qRRVIBDHT3LHU421uhO2vsrFmzSnLPQRAEHQEzm+ju41r7riSBdTPbJr2djbKqQBXslel9LzSL5AHkluqLZofMRALgSFC2RdZHlpF1C7Jiasg7/b6C4h6PZT9f8LqypYAEQRAE5aNUgfUPoAf/Y8BHUfU6KB13NfBz5NYahqyVJiQI30TjbTNeQS6v76OmjB9DVoihQPv9yBIZhGIluwBXo1nvc1FB41rZGFJ820q4u4IgKBelSvHN4hWbIWsks0DOQf2yLgQ+iyrXG1FB4SDgmnReM7l76wXg8+n4UWm9JmTFdEu/MxXVo7yGihWN3Hp5++Y2shTftjLq3Ns6nHAGQbBhKJUlsl967ZP+HAnU75EALELWiSP31ej0uhilAWeWSxYDybrwfhu5wipQHGSrdM39qCtwN/Iq9Qrgl61tLlJ8gyAIykOpROQi4HB3H2xmNyBR6U6eTVWNxGIoSs3dGlkiD6H6j67IvXU5six2QvGR2chF1RP4Ufq+GvgUSvOtRjGYhWn9p9e10Y7ozsoI8QyCoNQU7c4ys++Y2VQzexBZAGZmK1CdSKd02gKUrtsJxTYmodhIbxQsP75gDzVoNO6hSGRAdSI3o2LFPyCx6Q78z903R+1Rnk9rrERurrfR0d1ZGR1VPIMgKB9FWSJmtgtwOKpOr0biAKomfxTVduyAsrD2AL6LakieQIF2Q6IyHVkZ/ZHbavP03UXA15Gr6mQkIm8gS2Y+eTDekEUD6rP1bSRCLfcb7qwgCIIyUKwlsidwk7uvdvflwD3o4T4cPfQHoFjIQlQY+BUkLo7cUG+guMYIJDSNqL5kKMq+Oif9zjTUCqUHmi0yH4lOxsKC9+Vo4RIEQRCshVI9eFci19XItOYfkFVQg4SqJ3Ac8GVkoXRC1kclskgeB/4LjEXFiBehwVM7AUeixotdUUHiYGCamd0I7JN+51rk2lra2uY29or1YgmLLAiC9lJUxXpyZ/0OuaqqkBvrlfT1UCQUr5NXondBlklNOncQ8HfkEuuLgu19US1II3A7io9MQxZIdyRSpwP/QG1OepEH7L+I2tD/092PbGW/UbEeBEFQJGurWC/WEjkAuaIWI5FYjALmNen7PyJX01LyAsMKVBA4AsUyjkZWx6p0zc7ImugEfBjFOCqQK2smEoz/pWt/j2IfuwBLkJtsBnKTBUEQBBuINotIQVB9KyQCTyFX0zGo2PBHyHoYhupDuqBiwuXABcAl6MF/HxKLrA1KDbJCfg98LV0Hcnl1c/ehZrYveZuTB5HwzEDCNBK4z8wq3b1pTfvvyCm+rREurSAI2kOb3Vlm9hVUUDga1XKMQEJyAfAT1H0X9LB/AaXz9kWWRHM6firwDSQ0jeSNFKcg8dgmHbsRWT2dkEVyNnAeyupajYSjC3mCwLPAj93972va/7hx43zChAltuucgCIKOTFkaMLr70e6+E3AVckPdhlqxLwQuRS6m25FbajnwK2S5zAY+jWIZBtyNmi6uRkLSL71vAr7HWzv8nquf9s3T+iuQy2wFEqhT0Jjclv8BTjGzCWY2Yf78+cXechAEQdCCYmIiDwG/M7OfpOsPQZlPy5CbKwuYg4Lj1chaOIG8eeIL6W9LlC7cFVkbP0QZXB9CGV9/QKLUhAL5P0RFjQuRNbQAWT7TkCD+DfggCry3Sriz1o9wcwVBsD4Um511HgqMz0WzP25HQvCT7BRkgTQji6E2/WUpvxeg2EkTio/UowysVSiFtyn9bYWyubJ28Vmjx4OB/0M9t+qRqwtgb3d/cG17rxky2occ/4s233NHJcQkCIK1ubOKFZHu7r7CzLqiosFTgE2Bw1Bb9q+j2eg9kEXxQxTb2AsJSyUShJ+hPliDkFtqYVonC7JDXol+JArYV7l7TzPLmjZ+AAXZK4BPuft1rew3UnyDIAiKpBwpvleY2bboAX+1uz9pZk3IjfXpdM5yJBjPAeen32oGfowKCTsDxyK3VCWyKB5FwXqQe+shZOGcjgL0s4GRZjYnrbcA9epyZNF0XtfGw51VHGGRBEHQGkUF1rOgurtv7e6ZC2sLFNQ+ARUe9kDi0Ckda0yfv4ZauE9HFsaz6ZyDUMpvE7JesvkkmWA8hoL4ILdXBXKBnYDEqTsxT6RsZDNJQoCDICiklP2m5iLXUhajmILaum+Cph3+G1kpWYffTdEEw77p82MovnIk8C0UMB+EmjwuQzUnJ6Zz+6bPXZGb7AFUKb9TaxuLBoxBEATloVSTDUHWxQoUF+kJPIKsimuBcWjUbT1yPTWnv/7IDfU6ErThwG9RqjDpnCUo7fdA5K7KBl71Tuv/I61TARxvZmeW8J6CIAiCtVBsK/hRKCPrUdQ/6wk092Mpqv+4HwlCBUrzHQxchhomvh+JzdXIUhlLXufxv7TerLTOSjRoqiuySgak87I6kl7AEShN+Bqg3t0vWdveIyZSHsK6C4KOSbHZWaNQbcbOyG31BApyD0GupiFIVD6G4hezUZruHOSmeg01XTwMWRmOhKEaCdMYZM00peNdkEVzVDpWh2IgoJhKL1Q5/6S7j13b3qNiPQiCoG2UpWIdmOHuz7p7MxKSa9x9R2RtvIZiFS+idN2voRYnPUi1I+7+edSosQkJzeUorjKUfGbIRUicKpAggURlobtbWmsTFDNZoxpGxXoQBEF5aE9gva7gfXPB56zZ4iKU8jvJ3W8ys9moQPAsoJeZnY+skBXIkvgCmi3yLMrKAnUHHpzWvAdlb10PHGFmT6ZzapA4Ger2u1bCnbXhCVdXEGy8lDKw3pIHUGdfzOwA5OY6CaX6OuqDdRR5gPxSFDjfJ302NFa3Ou2zKv0dhcbxTkrHOyExagL2ay2wHim+7yyRGhwEGy/lHCl7HnJXdUEC8Tp64DejQLkhKyILom+J2sOPJ+8A/CLqo9WUzqlOa/dA7i0HJqPYTDNwf2uB9UjxDYIgKA9FBdbXe3EF4KcDN6GH/myU5lsL3Ilmr7+CguIZ89L5xyKRqURurQNRx99VwL+QkHRFNSjNpOmJ7v42YSwUkcqeA8YO++KfSnqfwfoTAh4E7z3K0fZkfX50FIpjGCoCnIbSfuuRq+srKI4yKx1/FRUZnoeC55AHy1cjq+Zm5M46PK2bubqa03lZv6230HLGegluLyiSQrdWCEoQvPcpmyWSRGQGEoJhKKW3DvXGaiQfJjUVubJqUV3ITci6mI1mlHwDeAkVM74K7IaC9llAvRm5yjZBwtLD3Wtb7CUaMAZBEBRJuVJ8C3/gODObZGbPmNmfzeyjwA0o28qBvdFDfltkPXRGFgkoEysrIGxErqveqBfX6QXn1QDbp/Wq0DTFZpTdNRgJiPFW11gQBEFQRtrkzjKz41DNh6PsqO+gtiM7od5Xx6KH+q9R7ch2SKgOQ7GRnZBINCDBGIqq3PugavV9UZuTJmR5ZKnDPZGl0hfFTK5H9SO7ImunL2o3f7G7P7+2e4gU3/c24QILgncX6+3OMrPtkHWxh7svMLO+qHXJEhQcfxn4mLsfamY3ovYlA9Ll2SjbCnJx+BESoRnItdUfBdGXoroRR26rfsjCaEjX1wHXAR9BVetdyTv/Vrt717XdR1SsB0EQtI1SubPGA/9y9wUA7r4I2B3Insh/RkOnQHGLm5D1kXEX6uS7EgnBl5BQzEfC8lo6rwdwYdpbn3Q+aJrhG6hS/njUqPFCVGDoaY1WFTEq1oMgCMpDKbKz/odSbi8FSBZKNXI3NaKU3M4o5rFfuqaWfBxuz3Tev4HPpc9fQdbFMhQLAVlBi/QTNgHFPmaSt5JvBP5pZpXu3rSmzYY7a+Mg3FpB8O6gGHfW7u6+MInFVUhAKpB7qkc6ZziKf/RBYpCJ1Y2oXiTre1WHKtQfQC6tBuTSaiAXD0dtVG4DDk3XDEATE4el364hn+V+4NrmrMeM9Y2TEJUgKB8lqRNx9ylm9iPgvjQK9yngNOBPKJ4xFfisu79iZlehuMVv0m80oof/QpSuuzn5XJEnkGjMRS6prmhY1bnIgnkMGI2KEwchl9lEYCSqgC/s2fWH1gQkKtaDIAjKQ5vcWe5+NXB1QZbWzShL60RUDHirmc0HPosshJXIEumOBGI0Ki7cEj38h6BsrWdRgH5suu5OlA58ZPpuJ1QsmFkp+yKLZ28UiO+HrJDdzazK3VstOoRwZ3UU4h8KQbBhaHOdSHJrfRsY7+5jgDOAXwFXp1bwfyXFR9AD//70O46siAFoFntnJEBVwA7InWXpuguRZWHAJ1GtyLmoC3Alsl52IhcpkAXTDfhpyz1HA8aOR/xDIQg2DMUE1t+WpWVmu6NaEFCWVuGD/G5gK1QTUoNcWXPSd9UoeN4NFRcuRYH1h1Fh4TJUh7I56gC8NRKUvij+siyde3i69kR3f7zlhsOdFQRBUB7aZIkkN9a5wOdSZfooM/svqjC/w8yyavHuqPivB7JaBiCroiody9qS9EciUYlcUtkM9tORa6sOZWztg0TKkQXTDVkg1cilBRKowpTiIAiCoMystyVS4Mb6FAqmn4fcWNehQsK5yI11I3IzHYKyquYgq2JCeu2EAuyNSBD6IHHIXF5dUXrwUBQveRHFUi4jD8ZfiayQr6FxuqtRHcmTZra5uzes6T4iJhIUElZpELSPtrizMjfWQylL6ybkXlqEsrTuBTZF8z9qUOB7JLIoQEH019M5WSovyBqpQ4IyGFWir0DWzHwUiN8eGIcEpAE4GYlIBZq9vjcSmPrWBKSwi++4ceN8Qjw4giAISkJRDRjd/Wp33x5lVH0OGIge6gtR36wqcuvgCiQSmyC31xI05jZzXW2LXFM3IeH4PXJ3ZVbHbsgVljVirCzYdz2Kh2Sc29p+o2I9CIKgPLTFEvkvcIOZXVxQbPgwSsPth6rHZ6AHezMqDBwMfBDFLppQf633od5YU5GALEcxjp3IGy92RiLycvrdL6OAewNqEd+NfGTueNQyxdLvr5VwZwXlJNxjQUejVMWGWyPLY1+UrluBHvrjkagYslTmkruxLkX9r0alY11QnOQ1JEJbpzVOSNcvAS5HTRsvS8dOQllZI9Oan0CFiC33HkOpgg3Cmv6BEuISbKwUVWzY4vB4M9sF+B1q0z6DvK1JNit9NAqg74ssjJeQy2oVEo+sZclTKLC+Tbp+OrJcXkHusOPTmjugVimdUfC9Mp1/AAr+v4VI8Q2CICgPJRmP6+5PmNkSZG3UIbdULbIehqJYR1ZI+AYSjq+nV5CIPI0yuT6OLBlDbqtuyB0GCrgD7IgC8k3IAlqa1uoaFevBxkT8gyd4t1OqyYa7oId6T2RtVCA3ViYonv5WIlHpj+pIViEXVlZc+EngIRT3MGRZvIgskVWo2WPW9v1FZIH0SO+fQu1Uzmi5v6hYD96rjDr3tvhHT/CupiSWCLAneug/ih7qWWHhQBREz1rCGxKSmcBFwIMoU2scEgpD0xAHIUvmOWRhjEFWSGZ5VJJncC1N1xjQ6O4/b7m5cGcFQRCUh5JYIolp5JMH65FrK5tQuJJcQKaitiV9UfpuHXlwvIp8aFU1mhnSJ107HQ2yqknfZUH7QUhoVpEPsAqCIAg2AKWyRGYDB6IeV0tRfOMmVMMxHD30G5A1sVW6pgEFxYehjKoPIDH4NCpU3ARlamUjdoekdeYisboS+B7wOLAzCrIvXNdGIyYSBOsmrPVgfVnvoVRrXcTsNBTPGIyypAYiF1bhjPWlyBU1ELmzqpBbaggSl2bUEmUBskBAVssUlLo7mbwwcS6yPLZE1kgWiF/u7n3WtteYsR4EQdA2SjVjfV08ijKrpqM03znIvfQ6ck8tSt8ZEo5z0MApkCWyEMVFzkuvoBYpPdM1u6MWJ5VIiDI2A55Px1u1rKJiPQiCoDy02Z1lZmcDde5+qZldgoLepyG30pdRzCIbievANcDZKAbSOy2z1N3/YWYXps99kFurGRUUZqNx56C6jw8hwemU1rwXCVFzel9PPpN9rYQ7KwjKR7jBOh7FWCIPkLdfH4fE4TpUaFiT1vw3SuGtQAJSidJyf4Ue/J3NbAKyKAx4ElkrXVrsqTuKqzQhi2QUEqeh6fuFKE6yefqN7q1tOFJ8g2DDECnJHY82x0TMrBrFKnYCrkeup+NQq/eJwKnkAfGKdM7+KPA9FQ2fqkJV65uhgsS/AncBt5O3RWlGFsZqJCD1qFBxBBKc24CPIhGal46/CmzWstiwRYrv2FmzZrXpnoMgCDoya4uJtNmd5e4NZjYD9bR6GGVmfQwF1Z9EWVf9kVWyBLmnZiGLZBtkOSwFLkYdf/sBR6N04NVIbCqRMGQusOeQdTMR9dtyYI+C38jmj4AmKx61pv2HOysINj7CjfbOUWyK7wNoINSJ6CHeBz3Qv4xEYhqyMl5DwfD+qFvvD4Bvkbcx6YIC7p9GVkg9EqHeyDW1CM1o/xSybKpRVtYNyBo5M12zKRKea9z9bb2zogFjEGzcvNf/YfheFsH2iMi3gEdQ0NuQQNwGTEI1HtXo4f4yEphewFdRbOQuJCANyPLIAuON6fxdkeWxS1qnEVXCV6d1Tibv9jsofd9ALk5vISrWgyAIykOxQ6nucfdqd69FwfUF7v5T1IqkAWVSPZXeb49iGquQC6sOubBGIzdVNyQy3ZBrbOu0r3losuEWyMpYkl4N+AMSkjlp3WqUubVpMfcTBEEQFEcpKtYXobhHRg0KgO+NHvoLkIh0QXELR+3dRwLPokLDq9LxbVBK8GeB01FdyXAkPAcBdyDX2PuR6AwEPgNcmM7bs7UNtnRnvddN3yAIOh7vVg9KuyrWzew4NCRqGHrQHwHcST4zfS6KjbyMAu/Zj01DVkNTwXKNqA1KfbpmJhKIC1AQ/fl07CNIXLZI17yIGjACnOnuv2hln5GdFQRBUCRlqVg3s+1QIeDuaCBVF+AfKIPqfFLHXXdficSkGWVlTUL1Hq+TTz2sQe4rR0K0FLm8jkRjdpchq+ZD6XV1OrcKucUaCz4HQRAEG4j2PHTHA/9y9wVmdgWyEDZFMZBKVD8ywsweQz2uHAlGNlv9SiRCjen8xem8u5GoNJAH7nsiy6Y6rbMPcqPNRYIzDLm3Fq1r05HiGwRBR6OcrrD29s7qZWYvoPTcrdHD/1pkaQxP649CQW9QhtU0JAZfJ7coQGIyCw2l6oQsm7OQ2Bjqx5XNHHkmvc4FvkDeg2tMa5uMivUgCILy0B5L5L+oTmMEcDBwGXJBbYdcWQ3oQT86nTsXWSlfStfPQgH4RagD8GzgFlR/8nfUuXcAEp6lwD3AF1Egvg6JzmQkYFmvrf1bG48bKb5BEATlob2B9bOAH6PA+RAkFjsgt9Z8lEm1PbIcsi6781BW1TnIJbYzKi5sQIHzbqjOpBMSls7p+znk6cGglN9e6fcuRbGT1cDl7v7VFvt8U0Qqew4YO+yLfyr6noMgCN5rtPcfzuVsBf9v1APrIBQoXw5cguIby5BoPIZEZCVK6e2LxOB7aBBVNqlwJhpkNRtlXzUg4WlI++yCLJR/pXUnp+MXIGulGZjXUkAg3FlBEATlolzZTANQi/Yq5O7aBT3km5ALqxrVjDQg0fkKsjhORBXoTUgklqB6k/lIUE5DbixDwfWXkCtseVq/obXNhDsrCIKgPJRkKJW7z3T37QsOvUoeOP8qqioHubF6oYf9StTK/Tuokr0LSv+dR97J98m0Rwf+h0TpMtSjayVqAZ8Jx3XAC6W4nyAIgmD9KMl43LcsaDYKuM/dR6bPnwSORZlT30TNFHdC4nA7siz+CPwMzRv5O/AHd/9Cun4ZEqFxyM11C3AuyuKaDjyI4iQzgF3c/ZB17G85SjPuiPRHHQQ6KnH/cf8d9f7be+8j3X1Aa1+Uy501wsx2d/dHkItqDLqJs1HPq+vSed8ELkJuKoCbkVuqDsDM9kX9uH7u7q+a2SKUCTYMVarvhAL7n2jD3qauKUC0sWNmEzrqvUPcf9x/x73/ct57uURkKvAlM/sjarK4RXr9sLsvAEaZ2UwAd/+smY1DlsgY5MIaaWaTkMvqI+4+Ka17J1Dp7keb2R7ICnnQ3W9KgrNLme4nCIIgaIWSi4i7z0SFhy0Z1eK8UQXvJ5jZ7Sjb6xh3f3ANa3+m4P3DFMR03P1/KG4SBEEQbCBKElgvBe5+gbuPXJOAlJAryrz+u5mOfO8Q9x/333Ep272XPLAeBEEQdBzeNZZIEARB8N6jw4iImR1gZlPNbJqZnftO76ccmNkfzWyemU0uONbXzO4ys5fSa5903Mzs0vTfY5KZve+d23n7MbPhZnavmT1nZlPM7Ix0vKPcf2cze9zMnkn3f346vqmZPZbu8x9m1ikdr0mfp6XvR72jN1AizKzSzJ4ys1vT5w5z/2Y208yeNbOnzWxCOlb2//13CBExs0rgN8CBqA39UWa27Tu7q7JwFXBAi2PnAve4+2jUxDIT0ANRc8zRqJr/ct7bNAJnufu2wG4oO3BbOs791wHj3X0MSn0/wMx2Q1M/L3H3LVA7opPS+ScBi9PxS9J5GwNnoAF2GR3t/j/o7jsVpPOW/3//7r7R/6HBWXcUfP4G8I13el9lutdRwOSCz1OBIen9EFQnAxokdlRr520Mf6gP24c74v0DXVGq/PtRgVlVOv7m/w/QqOnd0/uqdJ6903tv530PSw/K8cCtqD1SR7r/mUD/FsfK/r//DmGJoK7ArxZ8fi0d6wgMcvfZ6f0c1JsMNuL/Jsk1sTNq/tlh7j+5cp5GrYPuQt21l3g+GqHwHt+8//R9Nk30vcwvUHfw5vS5Hx3r/h2408wmpn6BsAH+9x/jZDsQ7u5mtlGn45lZd1Rv9BV3X2Zmb363sd+/uzcBO5lZb+AGWq/X2igxs0NQF++JqfC4I7KXu79uZgOBu0wDA9+kXP/77yiWyOto0mLGsHSsIzDXzIYApNd56fhG99/EzKqRgPzV3a9PhzvM/We4+xLURXt3oLeZZf9YLLzHN+8/fd8LNUR9r7In8LHUCePvyKX1SzrO/ePur6fXeegfEbuyAf7331FE5AlgdMrU6AQcifp0dQRuBo5P749HsYLs+HEpS2M3YGmB2fuew2Ry/AF43t0vLviqo9z/gGSBYGZdUDzoeSQmR6TTWt5/9t/lCOC/npzj70Xc/RvuPszVCeNIdD/H0EHu38y6mVmP7D2wPxqnUf7//b/TwaANGHQ6CDVtfBn41ju9nzLd47VoqFcD8nGehPy896DZK3cDfdO5hjLWXkbDwsa90/tv573vhXzCk4Cn099BHej+dwSeSvc/GfhuOr4Z8DgwDQ10q0nHO6fP09L3m73T91DC/xb7Ard2pPtP9/lM+puSPeM2xP/+o2I9CIIgKJqO4s4KgiAIykCISBAEQVA0ISJBEARB0YSIBEEQBEUTIhIEQRAUTYhIEARBUDQhIkEQBEHRhIgEQRAERfP/tJnafZf34dsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_birds = list(train_df.primary_label.dropna().unique())\n",
    "print('Total number of birds',len(all_birds))\n",
    "\n",
    "#load scored birds \n",
    "with open(Scored_Bird_DIR) as sbfile:\n",
    "    scored_birds = json.load(sbfile)\n",
    "print('Scored birds',scored_birds)\n",
    "\n",
    "bird_training_sample = train_df.primary_label.value_counts()\n",
    "\n",
    "print('Number of scored birds training files \\n',bird_training_sample.loc[scored_birds])\n",
    "print()\n",
    "print('Number of training files per bird')\n",
    "bird_training_sample.plot(kind='barh')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dab7b538",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/152 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './train_pt/afrsil1.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18184/1634106935.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mnum_training_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mbird\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_birds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_bird\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_spectograms_from_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbird2idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbird\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mnum_training_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbird\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train_bird\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0msorted_training_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_training_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mkv\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mkv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18184/582581834.py\u001b[0m in \u001b[0;36mget_spectograms_from_file\u001b[1;34m(idx)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mbird\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0midx2bird\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mpt_filepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrain_pt_DIR\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbird\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\".pt\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpt_filepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m216\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mnum_training_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m#y_train is one hot encoded vector per training sample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    697\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoding'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'w'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './train_pt/afrsil1.pt'"
     ]
    }
   ],
   "source": [
    "#EDA, did the number of training data (5s) per bird\n",
    "num_training_data = {}\n",
    "for bird in tqdm(all_birds):\n",
    "    _, y_train_bird = get_spectograms_from_file(bird2idx[bird])\n",
    "    num_training_data[bird] = len(y_train_bird)\n",
    "sorted_training_data = sorted(num_training_data.items(), key = lambda kv: kv[1])\n",
    "print(sorted_training_data)\n",
    "\n",
    "scored_bird_training = {}\n",
    "for bird in tqdm(scored_birds):\n",
    "    scored_bird_training[bird] = num_training_data[bird]\n",
    "sorted_scored_bird_training_data = sorted(scored_bird_training.items(), key = lambda kv: kv[1])\n",
    "print(sorted_scored_bird_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0579ea31",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sorted_training_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-c110832cd3a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msorted_training_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msorted_scored_bird_training_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sorted_training_data' is not defined"
     ]
    }
   ],
   "source": [
    "x, y = zip(*sorted_training_data) \n",
    "plt.plot(x, y)\n",
    "plt.show()\n",
    "\n",
    "x, y = zip(*sorted_scored_bird_training_data) \n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9460921",
   "metadata": {},
   "source": [
    "### Generate training data in .pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b41035d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectograms(filename):\n",
    "    chunk_duration = 5 #5sec chunk\n",
    "    duration = librosa.get_duration(filename=filename)\n",
    "    num_spectogram = int(duration/chunk_duration)\n",
    "    spectograms = []\n",
    "    for i in range(num_spectogram):\n",
    "        y, sr = librosa.load(filename, offset=i*chunk_duration, duration=chunk_duration)\n",
    "        #display(\"Old Audio\", ipd.Audio(data=y, rate=sr))\n",
    "        nr_y, nr_sr = noise_reduction(y, sr, plot=False, th=0.3)\n",
    "        #display(\"New Audio\", ipd.Audio(data=nr_y, rate=sr))\n",
    "        S = librosa.feature.melspectrogram(y=nr_y, sr=nr_sr)\n",
    "        S_DB = librosa.power_to_db(S, ref=np.max)\n",
    "        spectograms.append(S_DB)\n",
    "    return spectograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ff9c339",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/14852 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './train_audio/afrsil1/XC125458.ogg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mC:\\users\\jaivignesh venugopal\\.pyenv\\pyenv-win\\versions\\3.6.8\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mget_duration\u001b[1;34m(y, sr, S, n_fft, hop_length, center, filename)\u001b[0m\n\u001b[0;32m    712\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 713\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mduration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    714\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\users\\jaivignesh venugopal\\.pyenv\\pyenv-win\\versions\\3.6.8\\lib\\site-packages\\soundfile.py\u001b[0m in \u001b[0;36minfo\u001b[1;34m(file, verbose)\u001b[0m\n\u001b[0;32m    437\u001b[0m     \"\"\"\n\u001b[1;32m--> 438\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_SoundFileInfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\users\\jaivignesh venugopal\\.pyenv\\pyenv-win\\versions\\3.6.8\\lib\\site-packages\\soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file, verbose)\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mSoundFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    384\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\users\\jaivignesh venugopal\\.pyenv\\pyenv-win\\versions\\3.6.8\\lib\\site-packages\\soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    628\u001b[0m                                          format, subtype, endian)\n\u001b[1;32m--> 629\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    630\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'r+'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\users\\jaivignesh venugopal\\.pyenv\\pyenv-win\\versions\\3.6.8\\lib\\site-packages\\soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1183\u001b[0m         _error_check(_snd.sf_error(file_ptr),\n\u001b[1;32m-> 1184\u001b[1;33m                      \"Error opening {0!r}: \".format(self.name))\n\u001b[0m\u001b[0;32m   1185\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode_int\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_snd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSFM_WRITE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\users\\jaivignesh venugopal\\.pyenv\\pyenv-win\\versions\\3.6.8\\lib\\site-packages\\soundfile.py\u001b[0m in \u001b[0;36m_error_check\u001b[1;34m(err, prefix)\u001b[0m\n\u001b[0;32m   1356\u001b[0m         \u001b[0merr_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msf_error_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1357\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0m_ffi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'replace'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error opening './train_audio/afrsil1/XC125458.ogg': System error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-d702e969d750>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m#print('previous_bird',previous_bird)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m#print('current_bird',current_bird)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mspectograms_list\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mget_spectograms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dir'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnum_audio_files\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspectograms_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'./train_pt/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mcurrent_bird\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-36-0fae119c9372>\u001b[0m in \u001b[0;36mget_spectograms\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_spectograms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mchunk_duration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m \u001b[1;31m#5sec chunk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mduration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_duration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mnum_spectogram\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mduration\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mchunk_duration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mspectograms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\users\\jaivignesh venugopal\\.pyenv\\pyenv-win\\versions\\3.6.8\\lib\\site-packages\\librosa\\util\\decorators.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\users\\jaivignesh venugopal\\.pyenv\\pyenv-win\\versions\\3.6.8\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mget_duration\u001b[1;34m(y, sr, S, n_fft, hop_length, center, filename)\u001b[0m\n\u001b[0;32m    713\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mduration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 715\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0maudioread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfdesc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    716\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfdesc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mduration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\users\\jaivignesh venugopal\\.pyenv\\pyenv-win\\versions\\3.6.8\\lib\\site-packages\\audioread\\__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[1;34m(path, backends)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mBackendClass\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mBackendClass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\users\\jaivignesh venugopal\\.pyenv\\pyenv-win\\versions\\3.6.8\\lib\\site-packages\\audioread\\rawread.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \"\"\"\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './train_audio/afrsil1/XC125458.ogg'"
     ]
    }
   ],
   "source": [
    "#generate pt files\n",
    "num_audio_files = train_df.shape[0]\n",
    "\n",
    "spectograms_list = []\n",
    "for i in tqdm(range(num_audio_files)):\n",
    "    current_bird = train_df.primary_label.loc[i]\n",
    "    #print('previous_bird',previous_bird)\n",
    "    #print('current_bird',current_bird)\n",
    "    spectograms_list += get_spectograms(train_df['dir'].iloc[i])\n",
    "    if i+1 == num_audio_files:\n",
    "        torch.save(torch.tensor(np.array(spectograms_list)), './train_pt/'+current_bird+'.pt')\n",
    "    else:\n",
    "        next_bird = train_df.primary_label.loc[i+1]\n",
    "        #print('next_bird',next_bird)\n",
    "        if next_bird != current_bird:\n",
    "            torch.save(torch.tensor(np.array(spectograms_list)), './train_pt/'+current_bird+'.pt')\n",
    "            spectograms_list = []\n",
    "    previous_bird = current_bird\n",
    "    #print(spectograms_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913a4ddf",
   "metadata": {},
   "source": [
    "### Get the audio rating for each of the training sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a25d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "num_audio_files = train_df.shape[0]\n",
    "\n",
    "def get_num_spectograms_per_audio(filename):\n",
    "    chunk_duration = 5 #5sec chunk\n",
    "    duration = librosa.get_duration(filename=filename)\n",
    "    num_spectogram = int(duration/chunk_duration)\n",
    "    \n",
    "    return num_spectogram\n",
    "\n",
    "bird_audio_rating_mapping = {}\n",
    "audio_rating_list = []\n",
    "for i in tqdm(range(num_audio_files)):\n",
    "    current_bird = train_df.primary_label.loc[i]\n",
    "    audio_rating = train_df['rating'].iloc[i]\n",
    "    if audio_rating == 0:\n",
    "        audio_rating = 2.5\n",
    "    num_spec = get_num_spectograms_per_audio(train_df['dir'].iloc[i])\n",
    "    audio_rating_list += [audio_rating]*num_spec\n",
    "    if i+1 == num_audio_files:\n",
    "        bird_audio_rating_mapping[current_bird] = audio_rating_list\n",
    "        #torch.save(torch.tensor(np.array(spectograms_list)), './train_pt/'+current_bird+'.pt')\n",
    "    else:\n",
    "        next_bird = train_df.primary_label.loc[i+1]\n",
    "        if next_bird != current_bird:\n",
    "            bird_audio_rating_mapping[current_bird] = audio_rating_list\n",
    "            #torch.save(torch.tensor(np.array(spectograms_list)), './train_pt/'+current_bird+'.pt')\n",
    "            audio_rating_list = []\n",
    "    previous_bird = current_bird\n",
    "\n",
    "#save the mapping into file\n",
    "rating_file = open(\"bird_audio_rating_mapping.pkl\", \"wb\")\n",
    "pickle.dump(bird_audio_rating_mapping, rating_file)\n",
    "rating_file.close()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "406a07a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_file = open(Audio_Rating_Dir, \"rb\")\n",
    "bird_audio_rating_mapping = pickle.load(rating_file)\n",
    "#print(bird_audio_rating_mapping)\n",
    "rating_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cbfaedf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 3.0, 3.0, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0]\n",
      "90\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'num_training_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-2f4b9efe7f52>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbird_audio_rating_mapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'blknod'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbird_audio_rating_mapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'blknod'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_training_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'blknod'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'num_training_data' is not defined"
     ]
    }
   ],
   "source": [
    "print(bird_audio_rating_mapping['blknod'])\n",
    "print(len(bird_audio_rating_mapping['blknod']))\n",
    "print((num_training_data['blknod']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841678bc",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25ce365a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 147, 116, 102, 3, 130, 34, 98, 67, 148, 24, 48, 32, 134, 0, 128, 91, 22, 66, 14, 120, 49, 37, 72, 63, 131, 78, 53, 45, 52, 64, 2, 129, 107, 55, 104, 95, 50, 93, 26, 103, 21, 112, 121, 105, 136, 81, 113, 29, 90, 79, 82, 4, 25, 97, 87, 80, 47, 124, 11, 30, 142, 144, 92, 85, 135, 60, 115, 99, 139, 51, 140, 43, 123, 15, 138, 149, 88, 143, 42, 40, 61, 65, 54, 18, 35, 20, 84, 117, 8, 68, 77, 132, 76, 137, 146, 36, 100, 125, 127, 110, 145, 39, 28, 71, 75, 109, 9, 44, 122, 33, 13, 1, 17, 94, 119, 151, 114, 16, 10, 38, 23, 70, 31, 12, 69, 62, 46, 133, 57, 73, 126, 19, 74, 106, 118, 141, 108, 96, 27, 41, 56, 111, 6, 150, 83, 89, 58, 5, 7, 59, 86]\n",
      "\n",
      "['omao', 'whttro', 'refboo', 'osprey', 'akiapo', 'shtsan', 'chbsan', 'norsho', 'houfin', 'wiltur', 'buffle', 'eurwig', 'caster1', 'sooter1', 'afrsil1', 'semplo', 'merlin', 'brtcur', 'hoomer', 'bkwpet', 'rinduc', 'fragul', 'cintea', 'jabwar', 'hawgoo', 'skylar', 'lcspet', 'gnwtea', 'dunlin', 'glwgul', 'hawhaw', 'akepa1', 'sheowl', 'peflov', 'grbher3', 'palila', 'norhar2', 'gadwal', 'moudov', 'burpar', 'pagplo', 'brnowl', 'reccar', 'rinphe', 'parjae', 'sora', 'lessca', 'redava', 'calqua', 'maupar', 'leasan', 'lesyel', 'akikik', 'bulpet', 'norpin', 'mallar3', 'leater1', 'ercfra', 'rudtur', 'belkin1', 'cangoo', 'wesmea', 'wetshe', 'mitpar', 'madpet', 'sopsku1', 'hawama', 'redpha1', 'nutman', 'towsol', 'gamqua', 'wantat1', 'coopet', 'rorpar', 'blkfra', 'sposan', 'yebcar', 'masboo', 'wessan', 'comwax', 'compea', 'hawcoo', 'hawpet1', 'golphe', 'brant', 'chemun', 'brnnod', 'lotjae', 'rempar', 'arcter', 'houspa', 'layalb', 'snogoo', 'laugul', 'spodov', 'whiter', 'chukar', 'oahama', 'ruff', 'sander', 'pomjae', 'whfibi', 'commyn', 'cacgoo1', 'incter1', 'kauama', 'pibgre', 'barpet', 'crehon', 'rocpig', 'categr', 'bknsti', 'akekee', 'bongul', 'norcar', 'ribgul', 'zebdov', 'redjun', 'blknod', 'bcnher', 'comgal1', 'bubsan', 'iiwi', 'canvas', 'bkbplo', 'hudgod', 'hawcre', 'elepai', 'sooshe', 'gresca', 'japqua', 'saffin', 'brnboo', 'kalphe', 'pecsan', 'rettro', 'warwhe1', 'perfal', 'normoc', 'buwtea', 'comsan', 'grefri', 'puaioh', 'aniani', 'yefcan', 'lobdow', 'mauala', 'gryfra', 'amewig', 'apapan', 'gwfgoo', 'magpet1']\n"
     ]
    }
   ],
   "source": [
    "training_seq = [i for i in range(len(all_birds))]\n",
    "random.shuffle(training_seq)\n",
    "print(training_seq)\n",
    "print()\n",
    "training_seq_bird = [idx2bird[i] for i in training_seq]\n",
    "print(training_seq_bird)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deded270",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46592f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = r-a  # free inside reserved\n",
    "print(t)\n",
    "print(r)\n",
    "print(a)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4edca49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For upsampling / downsampling / mixup of data\n",
    "TRAINING_THRESHOLD_UPSAMPLING = 512\n",
    "TRAINING_THRESHOLD_DOWNSAMPLING = 512 * 2\n",
    "TRAINING_MIXUP_PERCENTAGE = 0.2 #0.2 means 20% of the training data (after up and down sampling) will be mixup \n",
    "TRAINING_SPECAUGMENT_PERCENTAGE = 0.2 #0.2 means 20% of the training data (after up and down sampling) will be spec-augment \n",
    "TRAINING_VAL_SPLIT = 0.8 #0.8 means 80% of training data will be considered for training, 20% for validation (untouched)\n",
    "\n",
    "def get_more_samples_raw(X_train_bird,y_train_bird,additional_num_samples,rating_weights):\n",
    "    #x train\n",
    "    #e.g. i need 512, but i only have 500\n",
    "    #total_samples = len(y_train_bird)\n",
    "    indices = torch.multinomial(rating_weights,additional_num_samples,replacement=True) #generate the random index, \n",
    "    #e.g. [0,99,54,46,56,35,245,6,8,8,2]\n",
    "    #indices = torch.randint(0,total_samples,(additional_num_samples,))\n",
    "\n",
    "    additional_X_train_bird = X_train_bird[indices]\n",
    "    additional_y_train_bird = y_train_bird[indices]\n",
    "    \n",
    "    return additional_X_train_bird, additional_y_train_bird\n",
    "\n",
    "def get_down_samples(X_train_bird,y_train_bird,num_samples,rating_weights):\n",
    "    #x train\n",
    "    # i got 2000 samples, retrieve only 1024\n",
    "    indices = torch.multinomial(rating_weights,num_samples)\n",
    "\n",
    "    updated_X_train_bird = X_train_bird[indices]\n",
    "    updated_y_train_bird = y_train_bird[indices]\n",
    "    \n",
    "    return updated_X_train_bird, updated_y_train_bird\n",
    "\n",
    "def get_mixup_samples(X_train_bird,y_train_bird,num_mixup_sample,rating_weights,TRAINING_VAL_SPLIT):\n",
    "    \n",
    "    #randomly select indices from bird type 1\n",
    "    source_indices = torch.randint(0,len(y_train_bird),(num_mixup_sample,))\n",
    "    source_X_train = X_train_bird[source_indices]\n",
    "    source_y_train = y_train_bird[source_indices]\n",
    "\n",
    "    #--- TARGET BIRD ---\n",
    "    #randomly select target bird type to mixup\n",
    "    target_bird = torch.randint(0,len(all_birds),(num_mixup_sample,)) #output [10,4,7,64,32]\n",
    "    bird_count = torch.bincount(target_bird) # output from bird1 - 4 times, bird 2 - 20 times \n",
    "    \n",
    "    #initialise empty tensor\n",
    "    target_X_train = torch.empty(0,X_train_bird.shape[1],X_train_bird.shape[2],X_train_bird.shape[3]) # N, C , H, W\n",
    "    target_y_train = torch.empty(0,len(all_birds))\n",
    "    for i in range(len(bird_count)):\n",
    "        if bird_count[i] >0:\n",
    "            add_target_X_train, add_target_y_train = get_n_training_spectograms_from_file(i, bird_count[i],TRAINING_VAL_SPLIT) #touched val_data, to be revised\n",
    "            target_X_train = torch.cat((target_X_train,add_target_X_train),0)\n",
    "            target_y_train = torch.cat((target_y_train,add_target_y_train),0)\n",
    "    \n",
    "    #Perform Mixup for source and target bird entries\n",
    "    mixup_X_train = torch.zeros(num_mixup_sample,X_train_bird.shape[1],X_train_bird.shape[2],X_train_bird.shape[3])\n",
    "    mixup_y_train = torch.zeros_like(target_y_train)\n",
    "    for i in range(len(source_indices)):\n",
    "        lambda_factor = torch.randn(1) \n",
    "        mixup_X_train[i] = source_X_train[i]*lambda_factor + target_X_train[i]*(1-lambda_factor)\n",
    "        mixup_y_train[i] = source_y_train[i]*lambda_factor + target_y_train[i]*(1-lambda_factor)\n",
    "\n",
    "    return mixup_X_train, mixup_y_train\n",
    "\n",
    "def spec_augment(spec, num_mask=1, \n",
    "                 freq_masking_max_percentage=0.1, time_masking_max_percentage=0.1):\n",
    "    \n",
    "    spec = spec.detach().clone()\n",
    "    for i in range(num_mask):\n",
    "        all_frames_num, all_freqs_num = spec.shape\n",
    "        freq_percentage = random.uniform(0.0, freq_masking_max_percentage)\n",
    "        \n",
    "        num_freqs_to_mask = int(freq_percentage * all_freqs_num)\n",
    "        f0 = np.random.uniform(low=0.0, high=all_freqs_num - num_freqs_to_mask)\n",
    "        f0 = int(f0)\n",
    "        spec[:, f0:f0 + num_freqs_to_mask] = 0\n",
    "\n",
    "        time_percentage = random.uniform(0.0, time_masking_max_percentage)\n",
    "        \n",
    "        num_frames_to_mask = int(time_percentage * all_frames_num)\n",
    "        t0 = np.random.uniform(low=0.0, high=all_frames_num - num_frames_to_mask)\n",
    "        t0 = int(t0)\n",
    "        spec[t0:t0 + num_frames_to_mask, :] = 0\n",
    "    \n",
    "    return spec\n",
    "\n",
    "def get_specaugment_samples(X_train_bird,y_train_bird,num_specaugment_sample,rating_weights):\n",
    "    source_indices = torch.randint(0,len(y_train_bird),(num_specaugment_sample,))\n",
    "    specaugment_X_train = X_train_bird[source_indices]\n",
    "    specaugment_y_train = y_train_bird[source_indices]\n",
    "    \n",
    "    for i in range(num_specaugment_sample):\n",
    "        specaugment_X_train[i] = spec_augment(specaugment_X_train[i].squeeze()).view(1,X_train_bird.shape[2],X_train_bird.shape[3])\n",
    "\n",
    "    return specaugment_X_train, specaugment_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4271d43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs, batch_size, training_seq):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in (range(num_epochs)):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "        random.shuffle(training_seq)\n",
    "        \n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "            \n",
    "            #print(phase)\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            dataset_size =0\n",
    "        \n",
    "            for bird_idx in tqdm(training_seq):\n",
    "                X_bird, y_bird = get_spectograms_from_file(bird_idx) #get all training data for each bird\n",
    "                #split to train and val set \n",
    "                \n",
    "                train_index = int(TRAINING_VAL_SPLIT*len(y_bird)) #80:20 split for training and validation\n",
    "                if phase == 'train':\n",
    "                    #print('bird', idx2bird[bird_idx])\n",
    "                    #print('shape b4',X_bird.shape)\n",
    "                    X_train_bird = X_bird[0:train_index]\n",
    "                    y_train_bird = y_bird[0:train_index]\n",
    "                    \n",
    "                    bird = idx2bird[bird_idx] #get the rating weights for sampling\n",
    "                    rating_audio = bird_audio_rating_mapping[bird] #higher rating audio will have higher chance of being sampled\n",
    "                    rating_audio_tensor = torch.tensor(np.array(rating_audio))\n",
    "                    rating_weights = rating_audio_tensor[0:train_index]\n",
    "                    #print('shape 1',X_bird.shape)\n",
    "                    #upsampling and downsampling for each bird\n",
    "                    if len(y_train_bird) < TRAINING_THRESHOLD_UPSAMPLING:\n",
    "                        additional_num_samples = TRAINING_THRESHOLD_UPSAMPLING - len(y_train_bird) \n",
    "                        additional_X_train_bird, additional_y_train_bird = get_more_samples_raw(X_train_bird,y_train_bird,additional_num_samples,rating_weights)\n",
    "                        X_train_bird = torch.cat((X_train_bird,additional_X_train_bird),0)\n",
    "                        y_train_bird = torch.cat((y_train_bird,additional_y_train_bird),0)\n",
    "                        #print('upsampling completed for ',idx2bird[bird_idx])\n",
    "                    elif len(y_train_bird) > TRAINING_THRESHOLD_DOWNSAMPLING:\n",
    "                        X_train_bird, y_train_bird = get_down_samples(X_train_bird,y_train_bird,TRAINING_THRESHOLD_DOWNSAMPLING,rating_weights)\n",
    "                        #print('downsampling completed for ',idx2bird[bird_idx])\n",
    "                    \n",
    "                    #print('shape 2',X_bird.shape)\n",
    "                    #perform mixup for each bird\n",
    "                    if TRAINING_MIXUP_PERCENTAGE > 0:\n",
    "                        #generate additional sample\n",
    "                        num_mixup_sample = int(len(y_train_bird) * TRAINING_MIXUP_PERCENTAGE)\n",
    "                        mixup_X_train_bird, mixup_y_train_bird = get_mixup_samples(X_train_bird,y_train_bird,num_mixup_sample,rating_weights,TRAINING_VAL_SPLIT)\n",
    "                        #print('mixup completed for ',idx2bird[bird_idx])\n",
    "                    \n",
    "                    if TRAINING_SPECAUGMENT_PERCENTAGE >0:\n",
    "                        num_specaugment_sample = int(len(y_train_bird) * TRAINING_SPECAUGMENT_PERCENTAGE)\n",
    "                        specaugment_X_train_bird, specaugment_y_train_bird = get_specaugment_samples(X_train_bird,y_train_bird,num_specaugment_sample,rating_weights)\n",
    "                        #print('specaugment_X_train_bird.shape',specaugment_X_train_bird.shape)\n",
    "                        \n",
    "                    if TRAINING_MIXUP_PERCENTAGE > 0:\n",
    "                        #add the generated samples\n",
    "                        X_train_bird = torch.cat((X_train_bird,mixup_X_train_bird),0)\n",
    "                        y_train_bird = torch.cat((y_train_bird,mixup_y_train_bird),0)\n",
    "                    \n",
    "                    if TRAINING_SPECAUGMENT_PERCENTAGE > 0:\n",
    "                        #add the generated samples\n",
    "                        X_train_bird = torch.cat((X_train_bird,specaugment_X_train_bird),0)\n",
    "                        y_train_bird = torch.cat((y_train_bird,specaugment_y_train_bird),0)\n",
    "                        \n",
    "                    #e.g.     X_train_bird.shape = (640,1,128,216)\n",
    "                    dataset_size += len(y_train_bird)\n",
    "                else:\n",
    "                    X_train_bird = X_bird[train_index:]\n",
    "                    y_train_bird = y_bird[train_index:]\n",
    "                    dataset_size += (len(y_bird)-train_index-1)\n",
    "                \n",
    "                num_batch = -(-len(y_train_bird)//batch_size) #e.g.10\n",
    "                for batch in (range(num_batch)):\n",
    "                    X_train = X_train_bird[batch*batch_size : (batch+1)*batch_size]\n",
    "                    y_train = y_train_bird[batch*batch_size : (batch+1)*batch_size]\n",
    "                    X_train = X_train.to(device)\n",
    "                    y_train = y_train.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    \n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(X_train)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, y_train.type(torch.float))\n",
    "                    \n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                    \n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * X_train.size(0)\n",
    "                    _,ground_truth = torch.max(y_train, 1)\n",
    "                    running_corrects += torch.sum(preds == ground_truth)\n",
    "                    \n",
    "                    #clear memory\n",
    "                    del X_train\n",
    "                    del y_train\n",
    "                    gc.collect()\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                    \n",
    "            #statistics\n",
    "            epoch_loss = running_loss / dataset_size\n",
    "            epoch_acc = running_corrects.double() / dataset_size\n",
    "            \n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "            time_elapsed = time.time() - since\n",
    "            print(f'Time_elapsed {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "            \n",
    "             # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "            torch.save(model.state_dict(), './last_model_parameters.pt')\n",
    "        print()\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7495f4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Epoch 0/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/152 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-458e632c4cba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;31m#model.load_state_dict(torch.load('./last_model_parameters.pt'))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-26-d315bce2a998>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, criterion, optimizer, num_epochs, batch_size, training_seq)\u001b[0m\n\u001b[0;32m     54\u001b[0m                         \u001b[1;31m#generate additional sample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m                         \u001b[0mnum_mixup_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train_bird\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mTRAINING_MIXUP_PERCENTAGE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m                         \u001b[0mmixup_X_train_bird\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmixup_y_train_bird\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_mixup_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_bird\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train_bird\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_mixup_sample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrating_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTRAINING_VAL_SPLIT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m                         \u001b[1;31m#print('mixup completed for ',idx2bird[bird_idx])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-ab28958726e9>\u001b[0m in \u001b[0;36mget_mixup_samples\u001b[1;34m(X_train_bird, y_train_bird, num_mixup_sample, rating_weights, TRAINING_VAL_SPLIT)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbird_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbird_count\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m             \u001b[0madd_target_X_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_target_y_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_n_training_spectograms_from_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbird_count\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTRAINING_VAL_SPLIT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#touched val_data, to be revised\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m             \u001b[0mtarget_X_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_X_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0madd_target_X_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0mtarget_y_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_y_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0madd_target_y_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-b5e659119b4e>\u001b[0m in \u001b[0;36mget_n_training_spectograms_from_file\u001b[1;34m(idx, n_spectograms, TRAINING_VAL_SPLIT)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mbird\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0midx2bird\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mpt_filepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrain_pt_DIR\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbird\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\".pt\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpt_filepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m216\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# to convert to N,C, H, W format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mtrain_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTRAINING_VAL_SPLIT\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#80:20 split for training and validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jaivignesh venugopal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    605\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 607\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    608\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jaivignesh venugopal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[0;32m    880\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 882\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jaivignesh venugopal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m    855\u001b[0m         \u001b[0mdata_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    856\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 857\u001b[1;33m             \u001b[0mload_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    858\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mstorage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jaivignesh venugopal\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[1;34m(data_type, size, key, location)\u001b[0m\n\u001b[0;32m    843\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    844\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 845\u001b[1;33m         \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    846\u001b[0m         \u001b[0mloaded_storages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# MODEL = 'resnet'\n",
    "MODEL = 'vit'\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "if MODEL == 'resnet':\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, len(all_birds))\n",
    "    model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    batch_size = 64\n",
    "    \n",
    "\n",
    "if MODEL == 'vit':\n",
    "    \n",
    "    efficient_transformer = Linformer(\n",
    "        dim=216,\n",
    "        seq_len=27649, # 128 * 216 + 1 cls token\n",
    "        depth=12,\n",
    "        heads=8,\n",
    "        k=64\n",
    "        )\n",
    "    \n",
    "    vit_model = ViT(\n",
    "        image_size=216,\n",
    "        patch_size=1,\n",
    "        num_classes=len(training_seq),\n",
    "        dim=216,\n",
    "        transformer=efficient_transformer,\n",
    "        channels=1\n",
    "        ).to(device)\n",
    "    \n",
    "    model = vit_model    \n",
    "    batch_size = 192    \n",
    "    \n",
    "#     LR = 0.001\n",
    "#     GAMMA = 0.7 #for learning rate scheduler \n",
    "#     scheduler = StepLR(optimizer, step_size=1, gamma=GAMMA)\n",
    "\n",
    "num_epochs = 50\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "#exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=1)\n",
    "\n",
    "#model.load_state_dict(torch.load('./last_model_parameters.pt'))\n",
    "best_model = train_model(model, criterion, optimizer, num_epochs, batch_size, training_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bd342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './best_model_parameters.pt')\n",
    "\n",
    "#model.load_state_dict(torch.load('./best_model_parameters.pt'))\n",
    "model.load_state_dict(torch.load('./last_model_parameters.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c499af63",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Audio_DIR = './test_soundscapes/'\n",
    "file_list = [f.split('.')[0] for f in sorted(os.listdir(Test_Audio_DIR))]\n",
    "\n",
    "print('Number of test soundscapes', len(file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a686919",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = {'row_id': [], 'target': []}\n",
    "threshold = 0.3\n",
    "model.eval() \n",
    "\n",
    "for file in file_list:\n",
    "    test_audio_file_path = test_audio_dir + file + '.ogg'\n",
    "    \n",
    "    chunk_duration = 5 #5sec chunk\n",
    "    duration = librosa.get_duration(filename=test_audio_file_path)\n",
    "    num_spectogram = int(duration/chunk_duration)\n",
    "    \n",
    "    chunks = [[] for i in range(num_spectogram)]\n",
    "\n",
    "    melspec_test = torch.tensor(get_spectograms(test_audio_file_path)).view(-1,1,128,216)\n",
    "    #X_test = torch.stack(melspec_test).to(device)\n",
    "    X_test = (melspec_test).to(device)\n",
    "    #print(X_test.shape)\n",
    "\n",
    "    outputs = model(X_test)\n",
    "    #print(outputs.shape)\n",
    "    outputs_test = torch.sigmoid(outputs)\n",
    "    #print(outputs_test.shape)\n",
    "    #print(scored_birds)\n",
    "\n",
    "    for idx, i in enumerate(range(len(chunks))):\n",
    "        chunk_end_time = (i + 1) * 5\n",
    "        for bird in scored_birds:\n",
    "            try:\n",
    "                score = outputs_test[idx][bird2idx[bird]]\n",
    "            except IndexError:\n",
    "                score = 0\n",
    "            \n",
    "            row_id = file + '_' + bird + '_' + str(chunk_end_time)\n",
    "            #print('score is ', score)\n",
    "            pred['row_id'].append(row_id)\n",
    "            pred['target'].append(True if score > threshold else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ac417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(pred, columns = ['row_id', 'target'])\n",
    "print(results)\n",
    "\n",
    "results.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e290e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
